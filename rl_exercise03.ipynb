{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RL Exercise 3 - Proximal Policy Optimization\n",
    "\n",
    "**GOAL:** The goal of this exercise is to demonstrate how to use the proximal policy optimization (PPO) algorithm.\n",
    "\n",
    "PPO is described in detail in https://arxiv.org/abs/1707.06347. It is a variant of Trust Region Policy Optimization (TRPO) described in https://arxiv.org/abs/1502.05477\n",
    "\n",
    "PPO works in two phases. In one phase, a large number of rollouts are performed (in parallel). The rollouts are then aggregated on the driver and a surrogate optimization objective is defined based on those rollouts. We then use SGD to find the policy that maximizes that objective with a penalty term for diverging too much from the current policy.\n",
    "\n",
    "**NOTE:** The SGD optimization step is best performed in a data-parallel manner over multiple GPUs. This is exposed through the `devices` field of the `config` dictionary (for this to work, you must be using a machine that has GPUs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import gym\n",
    "import ray\n",
    "from ray.rllib.ppo import PPOAgent, DEFAULT_CONFIG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start up Ray. This must be done before we instantiate any RL agents. We pass in `num_workers=0` because the training agent's constructor will create a number of actors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for redis server at 127.0.0.1:24039 to respond...\n",
      "Waiting for redis server at 127.0.0.1:10890 to respond...\n",
      "Warning: Reducing object store memory because /dev/shm has only 66178252800 bytes available. You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you may need to pass an argument with the flag '--shm-size' to 'docker run'.\n",
      "Starting local scheduler with 40 CPUs, 0 GPUs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'local_scheduler_socket_names': ['/tmp/scheduler76068844'],\n",
       " 'node_ip_address': '127.0.0.1',\n",
       " 'object_store_addresses': [ObjectStoreAddress(name='/tmp/plasma_store76850868', manager_name='/tmp/plasma_manager96617492', manager_port=54750)],\n",
       " 'redis_address': '127.0.0.1:24039',\n",
       " 'webui_url': ''}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init(num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate a PPOAgent object. We pass in a config object that specifies how the network and training procedure should be configured. Some of the parameters are the following.\n",
    "\n",
    "- `num_agents` is the number of actors that the agent will create. This determines the degree of parallelism that will be used.\n",
    "- `num_sgd_iter` is the number of epochs of SGD (passes through the data) that will be used to optimize the PPO surrogate objective at each iteration of PPO.\n",
    "- `sgd_batchsize` is the SGD batch size that will be used to optimize the PPO surrogate objective.\n",
    "- `model` contains a dictionary of parameters describing the neural net used to parameterize the policy. The `fcnet_hiddens` parameter is a list of the sizes of the hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-09-18 23:10:44,302] PPOAgent algorithm created with logdir '/tmp/ray/CartPole-v0_PPOAgent_2017-09-18_23-10-44b_15knyr'\n",
      "[2017-09-18 23:10:44,304] Making new env: CartPole-v0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-atari env, not using any observation preprocessor.\n",
      "Constructing fcnet [100, 100] <function tanh at 0x7f2bf7bd9268>\n",
      "Constructing fcnet [100, 100] <function tanh at 0x7f2bf7bd9268>\n",
      "Constructing fcnet [100, 100] <function tanh at 0x7f2bf7bd9268>\n",
      "Constructing fcnet [100, 100] <function tanh at 0x7f2bf7bd9268>\n",
      "Constructing fcnet [100, 100] <function tanh at 0x7f2bf7bd9268>\n",
      "Constructing fcnet [100, 100] <function tanh at 0x7f2bf7bd9268>\n",
      "Constructing fcnet [100, 100] <function tanh at 0x7f2bf7bd9268>\n",
      "Constructing fcnet [100, 100] <function tanh at 0x7f2bf7bd9268>\n",
      "Constructing fcnet [100, 100] <function tanh at 0x7f2bf7bd9268>\n",
      "Constructing fcnet [100, 100] <function tanh at 0x7f2bf7bd9268>\n"
     ]
    }
   ],
   "source": [
    "config = DEFAULT_CONFIG.copy()\n",
    "config['num_workers'] = 3\n",
    "config['num_sgd_iter'] = 30\n",
    "config['sgd_batchsize'] = 128\n",
    "config['model']['fcnet_hiddens'] = [100, 100]\n",
    "\n",
    "agent = PPOAgent('CartPole-v0', config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the policy on the `CartPole-v0` environment for 2 steps. The CartPole problem is described at https://gym.openai.com/envs/CartPole-v0.\n",
    "\n",
    "**EXERCISE:** Inspect how well the policy is doing by looking for the lines that say something like\n",
    "\n",
    "```\n",
    "total reward is  22.3215974777\n",
    "trajectory length mean is  21.3215974777\n",
    "```\n",
    "\n",
    "This indicates how much reward the policy is receiving and how many time steps of the environment the policy ran. The maximum possible reward for this problem is 200. The reward and trajectory length are very close because the agent receives a reward of one for every time step that it survives (however, that is specific to this environment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> iteration 1\n",
      "total reward is  21.9772138788\n",
      "trajectory length mean is  20.9772138788\n",
      "timesteps: 40507\n",
      "Computing policy (iterations=30, stepsize=5e-05):\n",
      "           iter     total loss    policy loss        vf loss             kl        entropy\n",
      "              0    3.01077e+02   -2.79731e-02    3.01101e+02    1.70152e-02    6.77316e-01\n",
      "              1    2.89601e+02   -4.36657e-02    2.89639e+02    2.85183e-02    6.66428e-01\n",
      "              2    2.59408e+02   -4.77955e-02    2.59449e+02    3.22889e-02    6.62838e-01\n",
      "              3    2.33537e+02   -4.93663e-02    2.33579e+02    3.36404e-02    6.61523e-01\n",
      "              4    2.10215e+02   -5.02108e-02    2.10258e+02    3.44015e-02    6.60779e-01\n",
      "              5    1.85847e+02   -5.08632e-02    1.85891e+02    3.48997e-02    6.60295e-01\n",
      "              6    1.56811e+02   -5.13301e-02    1.56855e+02    3.53625e-02    6.59846e-01\n",
      "              7    1.24922e+02   -5.17684e-02    1.24967e+02    3.58524e-02    6.59377e-01\n",
      "              8    9.83074e+01   -5.21176e-02    9.83522e+01    3.63988e-02    6.58858e-01\n",
      "              9    8.58306e+01   -5.24272e-02    8.58757e+01    3.68515e-02    6.58429e-01\n",
      "             10    8.00611e+01   -5.26659e-02    8.01063e+01    3.73004e-02    6.58005e-01\n",
      "             11    7.64482e+01   -5.28717e-02    7.64935e+01    3.76525e-02    6.57669e-01\n",
      "             12    7.39900e+01   -5.30517e-02    7.40355e+01    3.80316e-02    6.57310e-01\n",
      "             13    7.23634e+01   -5.32128e-02    7.24089e+01    3.82798e-02    6.57072e-01\n",
      "             14    7.14116e+01   -5.33416e-02    7.14573e+01    3.84763e-02    6.56887e-01\n",
      "             15    7.06171e+01   -5.34811e-02    7.06628e+01    3.87234e-02    6.56648e-01\n",
      "             16    7.01508e+01   -5.35647e-02    7.01966e+01    3.88260e-02    6.56553e-01\n",
      "             17    6.99480e+01   -5.36723e-02    6.99939e+01    3.90426e-02    6.56347e-01\n",
      "             18    6.98675e+01   -5.37719e-02    6.99134e+01    3.91982e-02    6.56198e-01\n",
      "             19    6.98283e+01   -5.38377e-02    6.98743e+01    3.92902e-02    6.56108e-01\n",
      "             20    6.97617e+01   -5.38976e-02    6.98077e+01    3.94492e-02    6.55957e-01\n",
      "             21    6.96529e+01   -5.40075e-02    6.96990e+01    3.95797e-02    6.55834e-01\n",
      "             22    6.95738e+01   -5.40837e-02    6.96199e+01    3.96984e-02    6.55719e-01\n",
      "             23    6.95315e+01   -5.41157e-02    6.95777e+01    3.97689e-02    6.55651e-01\n",
      "             24    6.94943e+01   -5.41687e-02    6.95405e+01    3.98669e-02    6.55557e-01\n",
      "             25    6.94483e+01   -5.42095e-02    6.94945e+01    3.99491e-02    6.55477e-01\n",
      "             26    6.94187e+01   -5.43001e-02    6.94649e+01    4.00805e-02    6.55353e-01\n",
      "             27    6.93995e+01   -5.43559e-02    6.94459e+01    4.01869e-02    6.55251e-01\n",
      "             28    6.93860e+01   -5.44047e-02    6.94324e+01    4.02670e-02    6.55175e-01\n",
      "             29    6.93769e+01   -5.44484e-02    6.94233e+01    4.03194e-02    6.55123e-01\n",
      "kl div: 0.0403194\n",
      "kl coeff: 0.30000000000000004\n",
      "rollouts time: 9.85666823387146\n",
      "shuffle time: 0.007108449935913086\n",
      "load time: 0.022147655487060547\n",
      "sgd time: 19.6391384601593\n",
      "sgd examples/s: 2062.5650194469595\n",
      "total time so far: 45.161884784698486\n",
      "TrainingResult(experiment_id='b32557d3d86244739db14bbf8234ce61', training_iteration=1, episode_reward_mean=21.977213878819263, episode_len_mean=20.977213878819263, info={'kl_divergence': 0.040319353, 'kl_coefficient': 0.30000000000000004, 'rollouts_time': 9.85666823387146, 'shuffle_time': 0.007108449935913086, 'load_time': 0.022147655487060547, 'sgd_time': 19.6391384601593, 'sample_throughput': 2062.5650194469595}, timesteps_this_iter=40507, timesteps_total=40507, time_this_iter_s=29.531572580337524, time_total_s=29.531572580337524)\n",
      "===> iteration 2\n",
      "total reward is  53.5436766623\n",
      "trajectory length mean is  52.5436766623\n",
      "timesteps: 40301\n",
      "Computing policy (iterations=30, stepsize=5e-05):\n",
      "           iter     total loss    policy loss        vf loss             kl        entropy\n",
      "              0    7.67332e+02   -2.24653e-02    7.67350e+02    1.39222e-02    6.06044e-01\n",
      "              1    6.60519e+02   -2.67803e-02    6.60541e+02    1.83008e-02    5.94326e-01\n",
      "              2    5.99789e+02   -2.72492e-02    5.99811e+02    1.92598e-02    5.92142e-01\n",
      "              3    5.53605e+02   -2.74104e-02    5.53626e+02    1.95863e-02    5.91589e-01\n",
      "              4    5.15365e+02   -2.75477e-02    5.15387e+02    1.98036e-02    5.90954e-01\n",
      "              5    4.82370e+02   -2.76014e-02    4.82392e+02    2.00059e-02    5.90558e-01\n",
      "              6    4.53153e+02   -2.77077e-02    4.53175e+02    2.01993e-02    5.90101e-01\n",
      "              7    4.26945e+02   -2.77815e-02    4.26967e+02    2.03128e-02    5.89845e-01\n",
      "              8    4.03216e+02   -2.78220e-02    4.03238e+02    2.04931e-02    5.89506e-01\n",
      "              9    3.81597e+02   -2.79081e-02    3.81618e+02    2.06048e-02    5.89312e-01\n",
      "             10    3.61819e+02   -2.78927e-02    3.61841e+02    2.06188e-02    5.89285e-01\n",
      "             11    3.43698e+02   -2.79314e-02    3.43720e+02    2.06720e-02    5.89094e-01\n",
      "             12    3.27120e+02   -2.79708e-02    3.27142e+02    2.07360e-02    5.89002e-01\n",
      "             13    3.11946e+02   -2.79876e-02    3.11968e+02    2.07786e-02    5.88874e-01\n",
      "             14    2.98044e+02   -2.80240e-02    2.98066e+02    2.08529e-02    5.88749e-01\n",
      "             15    2.85237e+02   -2.80569e-02    2.85259e+02    2.09275e-02    5.88589e-01\n",
      "             16    2.73539e+02   -2.80697e-02    2.73560e+02    2.09853e-02    5.88430e-01\n",
      "             17    2.62935e+02   -2.80414e-02    2.62957e+02    2.08669e-02    5.88681e-01\n",
      "             18    2.53329e+02   -2.80913e-02    2.53351e+02    2.10033e-02    5.88464e-01\n",
      "             19    2.44635e+02   -2.81011e-02    2.44657e+02    2.10210e-02    5.88433e-01\n",
      "             20    2.36724e+02   -2.81153e-02    2.36746e+02    2.09744e-02    5.88444e-01\n",
      "             21    2.29510e+02   -2.81268e-02    2.29532e+02    2.10379e-02    5.88378e-01\n",
      "             22    2.23027e+02   -2.81175e-02    2.23049e+02    2.09835e-02    5.88445e-01\n",
      "             23    2.17282e+02   -2.81878e-02    2.17304e+02    2.11774e-02    5.88213e-01\n",
      "             24    2.12187e+02   -2.81116e-02    2.12208e+02    2.10212e-02    5.88352e-01\n",
      "             25    2.07670e+02   -2.81765e-02    2.07692e+02    2.11201e-02    5.88243e-01\n",
      "             26    2.03736e+02   -2.81665e-02    2.03758e+02    2.10275e-02    5.88358e-01\n",
      "             27    2.00358e+02   -2.81814e-02    2.00380e+02    2.11598e-02    5.88132e-01\n",
      "             28    1.97484e+02   -2.81554e-02    1.97505e+02    2.10699e-02    5.88336e-01\n",
      "             29    1.95096e+02   -2.81980e-02    1.95118e+02    2.11765e-02    5.88118e-01\n",
      "kl div: 0.0211765\n",
      "kl coeff: 0.45000000000000007\n",
      "rollouts time: 8.478245735168457\n",
      "shuffle time: 0.005837440490722656\n",
      "load time: 0.0017156600952148438\n",
      "sgd time: 18.3374342918396\n",
      "sgd examples/s: 2197.7447530887393\n",
      "total time so far: 71.99114346504211\n",
      "TrainingResult(experiment_id='b32557d3d86244739db14bbf8234ce61', training_iteration=2, episode_reward_mean=53.543676662320728, episode_len_mean=52.543676662320728, info={'kl_divergence': 0.021176536, 'kl_coefficient': 0.45000000000000007, 'rollouts_time': 8.478245735168457, 'shuffle_time': 0.005837440490722656, 'load_time': 0.0017156600952148438, 'sgd_time': 18.3374342918396, 'sample_throughput': 2197.7447530887393}, timesteps_this_iter=40301, timesteps_total=80808, time_this_iter_s=26.829118967056274, time_total_s=56.3606915473938)\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    result = agent.train()\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCISE:** The current network and training configuration are too large and heavy-duty for a simple problem like CartPole. Modify the configuration to use a smaller network and to speed up the optimization of the surrogate objective (fewer SGD iterations and a larger batch size should help)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-09-18 23:12:09,520] PPOAgent algorithm created with logdir '/tmp/ray/CartPole-v0_PPOAgent_2017-09-18_23-12-09oy02h5hq'\n",
      "[2017-09-18 23:12:09,521] Making new env: CartPole-v0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-atari env, not using any observation preprocessor.\n",
      "Constructing fcnet [100, 100] <function tanh at 0x7f2bf7bd9268>\n",
      "Constructing fcnet [100, 100] <function tanh at 0x7f2bf7bd9268>\n",
      "Constructing fcnet [100, 100] <function tanh at 0x7f2bf7bd9268>\n",
      "Constructing fcnet [100, 100] <function tanh at 0x7f2bf7bd9268>\n",
      "Constructing fcnet [100, 100] <function tanh at 0x7f2bf7bd9268>\n",
      "Constructing fcnet [100, 100] <function tanh at 0x7f2bf7bd9268>\n",
      "Constructing fcnet [100, 100] <function tanh at 0x7f2bf7bd9268>\n",
      "Constructing fcnet [100, 100] <function tanh at 0x7f2bf7bd9268>\n",
      "Constructing fcnet [100, 100] <function tanh at 0x7f2bf7bd9268>\n",
      "Constructing fcnet [100, 100] <function tanh at 0x7f2bf7bd9268>\n"
     ]
    }
   ],
   "source": [
    "config = DEFAULT_CONFIG.copy()\n",
    "config['num_workers'] = 3\n",
    "config['num_sgd_iter'] = 30\n",
    "config['sgd_batchsize'] = 128\n",
    "config['model']['fcnet_hiddens'] = [100, 100]\n",
    "\n",
    "agent = PPOAgent('CartPole-v0', config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCISE:** Train the agent and try to get a reward of 200. If it's training too slowly you may need to modify the config above to use fewer hidden units, a larger `sgd_batchsize`, a smaller `num_sgd_iter`, or a larger `num_workers`.\n",
    "\n",
    "This should take around 20 or 30 training iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### note use a simpler network 100x100 is overkill for this problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> iteration 3\n",
      "total reward is  129.39184953\n",
      "trajectory length mean is  128.39184953\n",
      "timesteps: 40957\n",
      "Computing policy (iterations=30, stepsize=5e-05):\n",
      "           iter     total loss    policy loss        vf loss             kl        entropy\n",
      "              0    1.03670e+03   -8.39487e-03    1.03671e+03    5.24551e-03    5.59758e-01\n",
      "              1    8.94730e+02   -9.88502e-03    8.94737e+02    6.27735e-03    5.53654e-01\n",
      "              2    8.15363e+02   -1.00116e-02    8.15370e+02    6.39050e-03    5.53428e-01\n",
      "              3    7.60303e+02   -1.00249e-02    7.60310e+02    6.34543e-03    5.54137e-01\n",
      "              4    7.20068e+02   -1.00716e-02    7.20075e+02    6.30446e-03    5.54078e-01\n",
      "              5    6.87645e+02   -9.95674e-03    6.87652e+02    6.01853e-03    5.55839e-01\n",
      "              6    6.59445e+02   -1.00523e-02    6.59452e+02    6.06512e-03    5.55622e-01\n",
      "              7    6.34159e+02   -1.00701e-02    6.34166e+02    6.10951e-03    5.55423e-01\n",
      "              8    6.11115e+02   -1.00092e-02    6.11123e+02    5.92756e-03    5.56666e-01\n",
      "              9    5.89763e+02   -1.00242e-02    5.89770e+02    5.93596e-03    5.56628e-01\n",
      "             10    5.70057e+02   -1.00523e-02    5.70065e+02    5.92864e-03    5.56860e-01\n",
      "             11    5.51931e+02   -9.90937e-03    5.51939e+02    5.65140e-03    5.58247e-01\n",
      "             12    5.35384e+02   -1.00057e-02    5.35392e+02    5.82619e-03    5.57709e-01\n",
      "             13    5.20267e+02   -9.98266e-03    5.20275e+02    5.72560e-03    5.58368e-01\n",
      "             14    5.06554e+02   -1.00160e-02    5.06562e+02    5.83233e-03    5.57504e-01\n",
      "             15    4.94055e+02   -1.00394e-02    4.94062e+02    5.78304e-03    5.57942e-01\n",
      "             16    4.82671e+02   -9.97800e-03    4.82679e+02    5.70021e-03    5.58354e-01\n",
      "             17    4.72235e+02   -1.00054e-02    4.72242e+02    5.70300e-03    5.58316e-01\n",
      "             18    4.62775e+02   -9.97030e-03    4.62782e+02    5.64877e-03    5.58952e-01\n",
      "             19    4.54121e+02   -1.00105e-02    4.54128e+02    5.66643e-03    5.58778e-01\n",
      "             20    4.46122e+02   -1.00452e-02    4.46130e+02    5.74697e-03    5.58552e-01\n",
      "             21    4.38581e+02   -1.00904e-02    4.38588e+02    5.83154e-03    5.58129e-01\n",
      "             22    4.31705e+02   -1.00027e-02    4.31712e+02    5.70051e-03    5.58425e-01\n",
      "             23    4.25451e+02   -9.99655e-03    4.25459e+02    5.65080e-03    5.59113e-01\n",
      "             24    4.19147e+02   -1.00479e-02    4.19155e+02    5.70506e-03    5.59006e-01\n",
      "             25    4.12895e+02   -1.00354e-02    4.12903e+02    5.66419e-03    5.59276e-01\n",
      "             26    4.07095e+02   -9.98700e-03    4.07102e+02    5.55101e-03    5.59577e-01\n",
      "             27    4.02118e+02   -1.00604e-02    4.02125e+02    5.71086e-03    5.59399e-01\n",
      "             28    3.98735e+02   -1.00197e-02    3.98742e+02    5.58931e-03    5.59783e-01\n",
      "             29    3.96280e+02   -1.01051e-02    3.96287e+02    5.72765e-03    5.58790e-01\n",
      "kl div: 0.00572765\n",
      "kl coeff: 0.45000000000000007\n",
      "rollouts time: 8.542566537857056\n",
      "shuffle time: 0.004433155059814453\n",
      "load time: 0.0015490055084228516\n",
      "sgd time: 18.51809811592102\n",
      "sgd examples/s: 2211.728210079362\n",
      "total time so far: 206.41942954063416\n",
      "TrainingResult(experiment_id='aaf6071946ae492eb28236dfaaae1b3c', training_iteration=3, episode_reward_mean=129.39184952978056, episode_len_mean=128.39184952978056, info={'kl_divergence': 0.0057276492, 'kl_coefficient': 0.45000000000000007, 'rollouts_time': 8.542566537857056, 'shuffle_time': 0.004433155059814453, 'load_time': 0.0015490055084228516, 'sgd_time': 18.51809811592102, 'sample_throughput': 2211.728210079362}, timesteps_this_iter=40957, timesteps_total=122130, time_this_iter_s=27.07417869567871, time_total_s=82.79799437522888)\n",
      "===> iteration 4\n",
      "total reward is  178.303030303\n",
      "trajectory length mean is  177.303030303\n",
      "timesteps: 40957\n",
      "Computing policy (iterations=30, stepsize=5e-05):\n",
      "           iter     total loss    policy loss        vf loss             kl        entropy\n",
      "              0    8.39691e+02   -9.66651e-04    8.39692e+02    8.01321e-04    5.45859e-01\n",
      "              1    6.60336e+02   -1.35770e-03    6.60337e+02    1.11106e-03    5.43741e-01\n",
      "              2    5.79243e+02   -1.52032e-03    5.79244e+02    1.05532e-03    5.45217e-01\n",
      "              3    5.26271e+02   -1.69432e-03    5.26272e+02    1.32338e-03    5.43623e-01\n",
      "              4    4.82925e+02   -1.79325e-03    4.82926e+02    1.24847e-03    5.44431e-01\n",
      "              5    4.45555e+02   -2.04057e-03    4.45557e+02    1.61670e-03    5.42971e-01\n",
      "              6    4.17099e+02   -2.00821e-03    4.17100e+02    1.41348e-03    5.45837e-01\n",
      "              7    3.96140e+02   -2.04947e-03    3.96141e+02    1.42682e-03    5.46146e-01\n",
      "              8    3.80201e+02   -2.23322e-03    3.80203e+02    1.71652e-03    5.45215e-01\n",
      "              9    3.67613e+02   -2.08580e-03    3.67614e+02    1.43735e-03    5.46936e-01\n",
      "             10    3.57355e+02   -2.23713e-03    3.57356e+02    1.64852e-03    5.45575e-01\n",
      "             11    3.49108e+02   -2.15291e-03    3.49110e+02    1.53561e-03    5.49002e-01\n",
      "             12    3.42280e+02   -2.23895e-03    3.42281e+02    1.58456e-03    5.47184e-01\n",
      "             13    3.36436e+02   -2.27365e-03    3.36437e+02    1.61364e-03    5.47584e-01\n",
      "             14    3.31286e+02   -2.27722e-03    3.31287e+02    1.62446e-03    5.48350e-01\n",
      "             15    3.26628e+02   -2.29397e-03    3.26629e+02    1.56740e-03    5.48965e-01\n",
      "             16    3.22319e+02   -2.35754e-03    3.22320e+02    1.69337e-03    5.47292e-01\n",
      "             17    3.18246e+02   -2.30287e-03    3.18247e+02    1.61346e-03    5.49539e-01\n",
      "             18    3.14475e+02   -2.36576e-03    3.14477e+02    1.64689e-03    5.49347e-01\n",
      "             19    3.10987e+02   -2.41668e-03    3.10988e+02    1.78437e-03    5.46732e-01\n",
      "             20    3.07667e+02   -2.44928e-03    3.07669e+02    1.86563e-03    5.49378e-01\n",
      "             21    3.04535e+02   -2.27896e-03    3.04536e+02    1.48470e-03    5.51020e-01\n",
      "             22    3.01528e+02   -2.36243e-03    3.01530e+02    1.62901e-03    5.50031e-01\n",
      "             23    2.98628e+02   -2.41840e-03    2.98630e+02    1.74452e-03    5.48483e-01\n",
      "             24    2.95704e+02   -2.40446e-03    2.95706e+02    1.70280e-03    5.49806e-01\n",
      "             25    2.92367e+02   -2.42207e-03    2.92369e+02    1.68222e-03    5.49247e-01\n",
      "             26    2.86970e+02   -2.54738e-03    2.86972e+02    1.90568e-03    5.48483e-01\n",
      "             27    2.78234e+02   -2.41975e-03    2.78236e+02    1.66837e-03    5.49446e-01\n",
      "             28    2.70619e+02   -2.47358e-03    2.70621e+02    1.74100e-03    5.48234e-01\n",
      "             29    2.66654e+02   -2.40183e-03    2.66655e+02    1.66339e-03    5.51418e-01\n",
      "kl div: 0.00166339\n",
      "kl coeff: 0.22500000000000003\n",
      "rollouts time: 8.472747087478638\n",
      "shuffle time: 0.0043163299560546875\n",
      "load time: 0.0017387866973876953\n",
      "sgd time: 18.609557390213013\n",
      "sgd examples/s: 2200.8583622488395\n",
      "total time so far: 233.5135052204132\n",
      "TrainingResult(experiment_id='aaf6071946ae492eb28236dfaaae1b3c', training_iteration=4, episode_reward_mean=178.30303030303031, episode_len_mean=177.30303030303031, info={'kl_divergence': 0.0016633887, 'kl_coefficient': 0.22500000000000003, 'rollouts_time': 8.472747087478638, 'shuffle_time': 0.0043163299560546875, 'load_time': 0.0017387866973876953, 'sgd_time': 18.609557390213013, 'sample_throughput': 2200.8583622488395}, timesteps_this_iter=40957, timesteps_total=163087, time_this_iter_s=27.093785762786865, time_total_s=109.89178013801575)\n",
      "===> iteration 5\n",
      "total reward is  198.210784314\n",
      "trajectory length mean is  197.210784314\n",
      "timesteps: 40231\n",
      "Computing policy (iterations=30, stepsize=5e-05):\n",
      "           iter     total loss    policy loss        vf loss             kl        entropy\n",
      "              0    1.29237e+03   -1.61293e-06    1.29237e+03    7.32988e-05    5.40657e-01\n",
      "              1    8.56099e+02   -9.05681e-05    8.56099e+02    2.33164e-04    5.50184e-01\n",
      "              2    6.23328e+02   -9.43319e-05    6.23328e+02    1.30970e-04    5.45789e-01\n",
      "              3    4.86276e+02   -2.26664e-04    4.86277e+02    3.36482e-04    5.50649e-01\n",
      "              4    4.08557e+02   -2.28471e-04    4.08558e+02    3.10610e-04    5.48113e-01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              5    3.64003e+02   -2.36821e-04    3.64003e+02    4.29094e-04    5.49663e-01\n",
      "              6    3.36252e+02   -3.32965e-04    3.36252e+02    5.41246e-04    5.48683e-01\n",
      "              7    3.17249e+02   -3.63815e-04    3.17250e+02    5.21005e-04    5.45170e-01\n",
      "              8    3.03187e+02   -4.30062e-04    3.03187e+02    5.80607e-04    5.45207e-01\n",
      "              9    2.92003e+02   -4.35611e-04    2.92004e+02    6.94037e-04    5.49425e-01\n",
      "             10    2.82733e+02   -4.49105e-04    2.82733e+02    7.46260e-04    5.49558e-01\n",
      "             11    2.74851e+02   -4.79854e-04    2.74851e+02    8.13771e-04    5.48289e-01\n",
      "             12    2.68060e+02   -4.90129e-04    2.68060e+02    7.86196e-04    5.49117e-01\n",
      "             13    2.62150e+02   -5.38677e-04    2.62151e+02    9.02211e-04    5.46629e-01\n",
      "             14    2.56928e+02   -5.87420e-04    2.56929e+02    9.57457e-04    5.49312e-01\n",
      "             15    2.52393e+02   -5.78309e-04    2.52394e+02    1.00914e-03    5.46277e-01\n",
      "             16    2.48491e+02   -6.43320e-04    2.48492e+02    1.18874e-03    5.53004e-01\n",
      "             17    2.45129e+02   -6.52588e-04    2.45130e+02    1.17245e-03    5.47011e-01\n",
      "             18    2.42275e+02   -6.81394e-04    2.42275e+02    1.07790e-03    5.44940e-01\n",
      "             19    2.39917e+02   -6.93220e-04    2.39917e+02    1.08958e-03    5.47900e-01\n",
      "             20    2.38011e+02   -7.34931e-04    2.38011e+02    1.39771e-03    5.50973e-01\n",
      "             21    2.36469e+02   -7.73748e-04    2.36470e+02    1.33394e-03    5.51771e-01\n",
      "             22    2.35198e+02   -7.51072e-04    2.35199e+02    1.25302e-03    5.46244e-01\n",
      "             23    2.34157e+02   -7.73189e-04    2.34158e+02    1.23552e-03    5.45322e-01\n",
      "             24    2.33241e+02   -7.86651e-04    2.33242e+02    1.30506e-03    5.50053e-01\n",
      "             25    2.32475e+02   -8.75959e-04    2.32475e+02    1.57777e-03    5.52590e-01\n",
      "             26    2.31813e+02   -8.06475e-04    2.31813e+02    1.41090e-03    5.44195e-01\n",
      "             27    2.31216e+02   -8.44206e-04    2.31216e+02    1.40720e-03    5.46196e-01\n",
      "             28    2.30679e+02   -8.27241e-04    2.30679e+02    1.60413e-03    5.50493e-01\n",
      "             29    2.30185e+02   -9.12456e-04    2.30186e+02    1.57040e-03    5.47594e-01\n",
      "kl div: 0.0015704\n",
      "kl coeff: 0.11250000000000002\n",
      "rollouts time: 8.360407829284668\n",
      "shuffle time: 0.004178524017333984\n",
      "load time: 0.0016336441040039062\n",
      "sgd time: 18.284485816955566\n",
      "sgd examples/s: 2200.2806315008866\n",
      "total time so far: 260.1697053909302\n",
      "TrainingResult(experiment_id='aaf6071946ae492eb28236dfaaae1b3c', training_iteration=5, episode_reward_mean=198.2107843137255, episode_len_mean=197.2107843137255, info={'kl_divergence': 0.0015704008, 'kl_coefficient': 0.11250000000000002, 'rollouts_time': 8.360407829284668, 'shuffle_time': 0.004178524017333984, 'load_time': 0.0016336441040039062, 'sgd_time': 18.284485816955566, 'sample_throughput': 2200.2806315008866}, timesteps_this_iter=40231, timesteps_total=203318, time_this_iter_s=26.656104564666748, time_total_s=136.5478847026825)\n",
      "===> iteration 6\n",
      "total reward is  194.880952381\n",
      "trajectory length mean is  193.880952381\n",
      "timesteps: 40715\n",
      "Computing policy (iterations=30, stepsize=5e-05):\n",
      "           iter     total loss    policy loss        vf loss             kl        entropy\n",
      "              0    5.10703e+02   -1.85927e-04    5.10703e+02    3.10394e-04    5.34878e-01\n",
      "              1    3.38053e+02   -5.86944e-04    3.38054e+02    9.42125e-04    5.29566e-01\n",
      "              2    2.75662e+02   -9.44284e-04    2.75663e+02    2.16909e-03    5.23766e-01\n",
      "              3    2.42953e+02   -1.21718e-03    2.42954e+02    3.14798e-03    5.19335e-01\n",
      "              4    2.23219e+02   -1.29595e-03    2.23220e+02    3.34818e-03    5.30307e-01\n",
      "              5    2.10340e+02   -1.43216e-03    2.10341e+02    3.64989e-03    5.26084e-01\n",
      "              6    2.01880e+02   -1.39162e-03    2.01881e+02    3.10365e-03    5.30743e-01\n",
      "              7    1.96243e+02   -1.55719e-03    1.96244e+02    3.76124e-03    5.25202e-01\n",
      "              8    1.92295e+02   -1.59795e-03    1.92296e+02    3.84437e-03    5.28978e-01\n",
      "              9    1.89301e+02   -1.65851e-03    1.89302e+02    3.69357e-03    5.33268e-01\n",
      "             10    1.86791e+02   -1.73266e-03    1.86792e+02    4.21168e-03    5.28162e-01\n",
      "             11    1.84581e+02   -1.79123e-03    1.84583e+02    4.24876e-03    5.31377e-01\n",
      "             12    1.82656e+02   -1.72988e-03    1.82658e+02    4.21856e-03    5.31498e-01\n",
      "             13    1.80937e+02   -1.81337e-03    1.80939e+02    4.34227e-03    5.29328e-01\n",
      "             14    1.79364e+02   -1.90053e-03    1.79365e+02    4.68832e-03    5.30849e-01\n",
      "             15    1.77960e+02   -1.92703e-03    1.77962e+02    4.74264e-03    5.31362e-01\n",
      "             16    1.76723e+02   -1.87985e-03    1.76724e+02    4.48109e-03    5.32435e-01\n",
      "             17    1.75594e+02   -1.91629e-03    1.75596e+02    4.35960e-03    5.33271e-01\n",
      "             18    1.74528e+02   -1.98080e-03    1.74529e+02    4.93894e-03    5.29592e-01\n",
      "             19    1.73538e+02   -1.93826e-03    1.73540e+02    4.37841e-03    5.36116e-01\n",
      "             20    1.72621e+02   -1.95007e-03    1.72622e+02    4.33043e-03    5.32080e-01\n",
      "             21    1.71759e+02   -2.00438e-03    1.71760e+02    4.39334e-03    5.31456e-01\n",
      "             22    1.70930e+02   -2.10298e-03    1.70932e+02    5.21579e-03    5.31856e-01\n",
      "             23    1.70191e+02   -2.13270e-03    1.70192e+02    5.03972e-03    5.36141e-01\n",
      "             24    1.69503e+02   -2.01594e-03    1.69504e+02    4.70167e-03    5.30516e-01\n",
      "             25    1.68887e+02   -2.08317e-03    1.68889e+02    4.58828e-03    5.35558e-01\n",
      "             26    1.68301e+02   -2.17767e-03    1.68303e+02    5.13863e-03    5.33913e-01\n",
      "             27    1.67781e+02   -2.05993e-03    1.67782e+02    4.61771e-03    5.33313e-01\n",
      "             28    1.67290e+02   -2.20873e-03    1.67292e+02    5.07738e-03    5.36216e-01\n",
      "             29    1.66822e+02   -2.14970e-03    1.66823e+02    4.97757e-03    5.31796e-01\n",
      "kl div: 0.00497757\n",
      "kl coeff: 0.05625000000000001\n",
      "rollouts time: 8.429033756256104\n",
      "shuffle time: 0.004509925842285156\n",
      "load time: 0.0013849735260009766\n",
      "sgd time: 18.60266613960266\n",
      "sgd examples/s: 2188.664769579617\n",
      "total time so far: 287.2128586769104\n",
      "TrainingResult(experiment_id='aaf6071946ae492eb28236dfaaae1b3c', training_iteration=6, episode_reward_mean=194.88095238095238, episode_len_mean=193.88095238095238, info={'kl_divergence': 0.0049775685, 'kl_coefficient': 0.05625000000000001, 'rollouts_time': 8.429033756256104, 'shuffle_time': 0.004509925842285156, 'load_time': 0.0013849735260009766, 'sgd_time': 18.60266613960266, 'sample_throughput': 2188.664769579617}, timesteps_this_iter=40715, timesteps_total=244033, time_this_iter_s=27.042917728424072, time_total_s=163.59080243110657)\n",
      "===> iteration 7\n",
      "total reward is  200.0\n",
      "trajectory length mean is  199.0\n",
      "timesteps: 40596\n",
      "Computing policy (iterations=30, stepsize=5e-05):\n",
      "           iter     total loss    policy loss        vf loss             kl        entropy\n",
      "              0    9.93600e+02    1.30362e-05    9.93600e+02    2.23150e-04    5.36570e-01\n",
      "              1    7.01437e+02   -1.45025e-04    7.01437e+02    5.22349e-04    5.32259e-01\n",
      "              2    5.43401e+02   -3.44813e-04    5.43401e+02    1.89953e-03    5.40442e-01\n",
      "              3    4.36132e+02   -5.09930e-04    4.36132e+02    2.71776e-03    5.45605e-01\n",
      "              4    3.60465e+02   -5.61539e-04    3.60465e+02    3.42824e-03    5.33856e-01\n",
      "              5    3.06191e+02   -6.34499e-04    3.06191e+02    3.37402e-03    5.37233e-01\n",
      "              6    2.73832e+02   -6.48037e-04    2.73833e+02    3.34785e-03    5.44700e-01\n",
      "              7    2.58623e+02   -6.21578e-04    2.58623e+02    2.90134e-03    5.33920e-01\n",
      "              8    2.51784e+02   -7.04991e-04    2.51784e+02    3.33605e-03    5.38037e-01\n",
      "              9    2.48179e+02   -6.83494e-04    2.48179e+02    2.95703e-03    5.35263e-01\n",
      "             10    2.45729e+02   -7.83409e-04    2.45730e+02    3.83233e-03    5.39651e-01\n",
      "             11    2.43999e+02   -7.12549e-04    2.44000e+02    2.95902e-03    5.31764e-01\n",
      "             12    2.42661e+02   -7.93590e-04    2.42662e+02    3.29616e-03    5.36930e-01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             13    2.41558e+02   -7.77707e-04    2.41558e+02    3.05840e-03    5.38185e-01\n",
      "             14    2.40667e+02   -7.61884e-04    2.40668e+02    3.39073e-03    5.35448e-01\n",
      "             15    2.39934e+02   -8.40998e-04    2.39935e+02    3.10428e-03    5.34660e-01\n",
      "             16    2.39271e+02   -8.45143e-04    2.39272e+02    2.86631e-03    5.39830e-01\n",
      "             17    2.38714e+02   -8.58843e-04    2.38714e+02    3.21907e-03    5.37720e-01\n",
      "             18    2.38212e+02   -9.09221e-04    2.38213e+02    3.27115e-03    5.41820e-01\n",
      "             19    2.37756e+02   -9.02058e-04    2.37756e+02    3.07555e-03    5.30887e-01\n",
      "             20    2.37329e+02   -9.34895e-04    2.37330e+02    3.37208e-03    5.39241e-01\n",
      "             21    2.36948e+02   -9.28508e-04    2.36949e+02    3.60381e-03    5.33110e-01\n",
      "             22    2.36593e+02   -8.85475e-04    2.36593e+02    2.81112e-03    5.29741e-01\n",
      "             23    2.36266e+02   -9.51372e-04    2.36267e+02    2.90725e-03    5.32365e-01\n",
      "             24    2.35982e+02   -9.25553e-04    2.35982e+02    3.02679e-03    5.36727e-01\n",
      "             25    2.35705e+02   -9.70486e-04    2.35706e+02    3.22942e-03    5.32554e-01\n",
      "             26    2.35454e+02   -9.71321e-04    2.35455e+02    3.21848e-03    5.36476e-01\n",
      "             27    2.35215e+02   -9.88487e-04    2.35215e+02    3.44837e-03    5.37078e-01\n",
      "             28    2.34981e+02   -1.00957e-03    2.34982e+02    3.40405e-03    5.34817e-01\n",
      "             29    2.34758e+02   -1.05399e-03    2.34759e+02    3.40258e-03    5.37898e-01\n",
      "kl div: 0.00340258\n",
      "kl coeff: 0.028125000000000004\n",
      "rollouts time: 8.529493570327759\n",
      "shuffle time: 0.0066127777099609375\n",
      "load time: 0.0020079612731933594\n",
      "sgd time: 18.432291507720947\n",
      "sgd examples/s: 2202.4391260845177\n",
      "total time so far: 314.1890218257904\n",
      "TrainingResult(experiment_id='aaf6071946ae492eb28236dfaaae1b3c', training_iteration=7, episode_reward_mean=200.0, episode_len_mean=199.0, info={'kl_divergence': 0.0034025824, 'kl_coefficient': 0.028125000000000004, 'rollouts_time': 8.529493570327759, 'shuffle_time': 0.0066127777099609375, 'load_time': 0.0020079612731933594, 'sgd_time': 18.432291507720947, 'sample_throughput': 2202.4391260845177}, timesteps_this_iter=40596, timesteps_total=284629, time_this_iter_s=26.975961208343506, time_total_s=190.56676363945007)\n",
      "===> iteration 8\n",
      "total reward is  199.985294118\n",
      "trajectory length mean is  198.985294118\n",
      "timesteps: 40593\n",
      "Computing policy (iterations=30, stepsize=5e-05):\n",
      "           iter     total loss    policy loss        vf loss             kl        entropy\n",
      "              0    6.38449e+02   -3.83115e-05    6.38449e+02    4.18750e-04    5.15440e-01\n",
      "              1    4.09048e+02   -1.55697e-04    4.09049e+02    7.11382e-04    5.10750e-01\n",
      "              2    3.39673e+02   -2.18650e-04    3.39673e+02    1.97785e-03    4.98042e-01\n",
      "              3    3.11375e+02   -3.06943e-04    3.11375e+02    2.84997e-03    4.91234e-01\n",
      "              4    2.97822e+02   -3.45476e-04    2.97823e+02    2.23401e-03    4.95502e-01\n",
      "              5    2.89163e+02   -4.79697e-04    2.89164e+02    3.63663e-03    4.86601e-01\n",
      "              6    2.82209e+02   -3.83978e-04    2.82210e+02    2.00984e-03    4.98329e-01\n",
      "              7    2.76032e+02   -4.23496e-04    2.76032e+02    2.75683e-03    4.92769e-01\n",
      "              8    2.70573e+02   -5.10062e-04    2.70573e+02    3.41824e-03    4.88138e-01\n",
      "              9    2.65748e+02   -4.79900e-04    2.65749e+02    3.25379e-03    4.89698e-01\n",
      "             10    2.61385e+02   -4.88258e-04    2.61386e+02    3.16034e-03    4.90333e-01\n",
      "             11    2.57452e+02   -4.77136e-04    2.57452e+02    2.33155e-03    4.96786e-01\n",
      "             12    2.53822e+02   -5.63558e-04    2.53823e+02    3.53923e-03    4.88166e-01\n",
      "             13    2.50454e+02   -5.53291e-04    2.50455e+02    3.28099e-03    4.91806e-01\n",
      "             14    2.47320e+02   -5.47164e-04    2.47321e+02    3.64246e-03    4.89117e-01\n",
      "             15    2.44350e+02   -6.15118e-04    2.44351e+02    4.33019e-03    4.85374e-01\n",
      "             16    2.41689e+02   -6.43021e-04    2.41689e+02    4.29005e-03    4.84404e-01\n",
      "             17    2.39400e+02   -5.89931e-04    2.39400e+02    3.57126e-03    4.89767e-01\n",
      "             18    2.37459e+02   -6.08626e-04    2.37460e+02    3.56271e-03    4.89028e-01\n",
      "             19    2.35878e+02   -6.89375e-04    2.35878e+02    4.26804e-03    4.85504e-01\n",
      "             20    2.34495e+02   -6.48207e-04    2.34496e+02    3.92492e-03    4.89688e-01\n",
      "             21    2.33260e+02   -6.61194e-04    2.33261e+02    3.60708e-03    4.90796e-01\n",
      "             22    2.32058e+02   -6.58817e-04    2.32059e+02    3.35650e-03    4.92917e-01\n",
      "             23    2.30873e+02   -7.38370e-04    2.30874e+02    4.41836e-03    4.87443e-01\n",
      "             24    2.29498e+02   -7.39980e-04    2.29499e+02    4.39373e-03    4.85642e-01\n",
      "             25    2.28033e+02   -7.35459e-04    2.28033e+02    4.08655e-03    4.87004e-01\n",
      "             26    2.26879e+02   -7.28907e-04    2.26880e+02    3.30277e-03    4.94606e-01\n",
      "             27    2.25884e+02   -7.38810e-04    2.25885e+02    4.28944e-03    4.86937e-01\n",
      "             28    2.25018e+02   -7.45064e-04    2.25018e+02    4.45669e-03    4.86399e-01\n",
      "             29    2.24251e+02   -8.44021e-04    2.24252e+02    4.40020e-03    4.86044e-01\n",
      "kl div: 0.0044002\n",
      "kl coeff: 0.014062500000000002\n",
      "rollouts time: 8.565053939819336\n",
      "shuffle time: 0.004156827926635742\n",
      "load time: 0.0014069080352783203\n",
      "sgd time: 18.399938344955444\n",
      "sgd examples/s: 2206.148696749793\n",
      "total time so far: 341.1651418209076\n",
      "TrainingResult(experiment_id='aaf6071946ae492eb28236dfaaae1b3c', training_iteration=8, episode_reward_mean=199.98529411764707, episode_len_mean=198.98529411764707, info={'kl_divergence': 0.0044002016, 'kl_coefficient': 0.014062500000000002, 'rollouts_time': 8.565053939819336, 'shuffle_time': 0.004156827926635742, 'load_time': 0.0014069080352783203, 'sgd_time': 18.399938344955444, 'sample_throughput': 2206.148696749793}, timesteps_this_iter=40593, timesteps_total=325222, time_this_iter_s=26.9759259223938, time_total_s=217.54268956184387)\n",
      "===> iteration 9\n",
      "total reward is  199.200980392\n",
      "trajectory length mean is  198.200980392\n",
      "timesteps: 40433\n",
      "Computing policy (iterations=30, stepsize=5e-05):\n",
      "           iter     total loss    policy loss        vf loss             kl        entropy\n",
      "              0    9.50000e+02    2.60037e-04    9.50000e+02    2.09213e-04    5.11152e-01\n",
      "              1    3.86508e+02    8.93513e-05    3.86508e+02    1.29175e-03    5.22236e-01\n",
      "              2    2.95601e+02   -1.43121e-04    2.95602e+02    1.52358e-03    5.22281e-01\n",
      "              3    2.75313e+02   -2.53734e-04    2.75313e+02    2.55723e-03    5.26442e-01\n",
      "              4    2.66252e+02   -4.29952e-04    2.66252e+02    3.72819e-03    5.34929e-01\n",
      "              5    2.59913e+02   -4.39223e-04    2.59913e+02    2.94675e-03    5.29917e-01\n",
      "              6    2.54933e+02   -5.44459e-04    2.54934e+02    3.89370e-03    5.32806e-01\n",
      "              7    2.50901e+02   -5.77933e-04    2.50902e+02    3.51205e-03    5.27617e-01\n",
      "              8    2.47635e+02   -6.69609e-04    2.47635e+02    4.53010e-03    5.33627e-01\n",
      "              9    2.44965e+02   -7.17501e-04    2.44966e+02    4.76955e-03    5.34167e-01\n",
      "             10    2.42772e+02   -7.21966e-04    2.42773e+02    4.36289e-03    5.31371e-01\n",
      "             11    2.40956e+02   -7.30813e-04    2.40957e+02    4.48423e-03    5.32988e-01\n",
      "             12    2.39466e+02   -7.65355e-04    2.39467e+02    3.88591e-03    5.22631e-01\n",
      "             13    2.38239e+02   -8.05102e-04    2.38239e+02    4.56964e-03    5.29140e-01\n",
      "             14    2.37209e+02   -8.80468e-04    2.37210e+02    5.01539e-03    5.31475e-01\n",
      "             15    2.36340e+02   -8.64709e-04    2.36341e+02    4.58374e-03    5.26475e-01\n",
      "             16    2.35581e+02   -8.98637e-04    2.35581e+02    4.82358e-03    5.23448e-01\n",
      "             17    2.34926e+02   -9.11251e-04    2.34927e+02    4.33265e-03    5.28501e-01\n",
      "             18    2.34319e+02   -8.85224e-04    2.34320e+02    5.14156e-03    5.27035e-01\n",
      "             19    2.33781e+02   -9.95289e-04    2.33782e+02    5.08953e-03    5.24496e-01\n",
      "             20    2.33294e+02   -9.52491e-04    2.33294e+02    4.36280e-03    5.25133e-01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             21    2.32830e+02   -1.02788e-03    2.32831e+02    5.69929e-03    5.29583e-01\n",
      "             22    2.32411e+02   -1.02138e-03    2.32412e+02    4.95867e-03    5.25160e-01\n",
      "             23    2.32026e+02   -9.84224e-04    2.32027e+02    4.58778e-03    5.20490e-01\n",
      "             24    2.31655e+02   -1.00555e-03    2.31656e+02    4.73769e-03    5.21648e-01\n",
      "             25    2.31356e+02   -1.08488e-03    2.31357e+02    4.84898e-03    5.29307e-01\n",
      "             26    2.31065e+02   -1.09590e-03    2.31066e+02    5.31661e-03    5.22858e-01\n",
      "             27    2.30767e+02   -1.06633e-03    2.30768e+02    4.90463e-03    5.24795e-01\n",
      "             28    2.30523e+02   -1.15467e-03    2.30524e+02    4.89859e-03    5.25682e-01\n",
      "             29    2.30221e+02   -1.06354e-03    2.30222e+02    4.68647e-03    5.15402e-01\n",
      "kl div: 0.00468647\n",
      "kl coeff: 0.007031250000000001\n",
      "rollouts time: 8.52013087272644\n",
      "shuffle time: 0.004523515701293945\n",
      "load time: 0.001699209213256836\n",
      "sgd time: 18.20466136932373\n",
      "sgd examples/s: 2221.024559574217\n",
      "total time so far: 367.9018461704254\n",
      "TrainingResult(experiment_id='aaf6071946ae492eb28236dfaaae1b3c', training_iteration=9, episode_reward_mean=199.20098039215685, episode_len_mean=198.20098039215685, info={'kl_divergence': 0.0046864748, 'kl_coefficient': 0.007031250000000001, 'rollouts_time': 8.52013087272644, 'shuffle_time': 0.004523515701293945, 'load_time': 0.001699209213256836, 'sgd_time': 18.20466136932373, 'sample_throughput': 2221.024559574217}, timesteps_this_iter=40433, timesteps_total=365655, time_this_iter_s=26.736629962921143, time_total_s=244.27931952476501)\n",
      "===> iteration 10\n",
      "total reward is  200.0\n",
      "trajectory length mean is  199.0\n",
      "timesteps: 40596\n",
      "Computing policy (iterations=30, stepsize=5e-05):\n",
      "           iter     total loss    policy loss        vf loss             kl        entropy\n",
      "              0    5.45226e+02    1.35919e-04    5.45226e+02    3.25608e-04    5.19021e-01\n",
      "              1    3.47216e+02   -1.75117e-04    3.47216e+02    1.82343e-03    5.27677e-01\n",
      "              2    3.14480e+02   -3.66949e-04    3.14480e+02    2.56440e-03    5.22429e-01\n",
      "              3    3.02244e+02   -4.46568e-04    3.02244e+02    2.37233e-03    5.23307e-01\n",
      "              4    2.94896e+02   -4.77696e-04    2.94896e+02    3.03277e-03    5.28801e-01\n",
      "              5    2.88636e+02   -5.77805e-04    2.88636e+02    3.31722e-03    5.18940e-01\n",
      "              6    2.82215e+02   -6.20937e-04    2.82216e+02    3.72118e-03    5.17174e-01\n",
      "              7    2.75733e+02   -6.31222e-04    2.75734e+02    3.50237e-03    5.20606e-01\n",
      "              8    2.69282e+02   -6.50678e-04    2.69282e+02    3.72805e-03    5.14173e-01\n",
      "              9    2.62415e+02   -6.54309e-04    2.62415e+02    3.96518e-03    5.16605e-01\n",
      "             10    2.55538e+02   -7.83712e-04    2.55539e+02    4.02661e-03    5.20147e-01\n",
      "             11    2.49886e+02   -7.47154e-04    2.49887e+02    4.05231e-03    5.17588e-01\n",
      "             12    2.45698e+02   -7.31592e-04    2.45699e+02    3.84006e-03    5.07947e-01\n",
      "             13    2.42460e+02   -8.29024e-04    2.42461e+02    4.57143e-03    5.16134e-01\n",
      "             14    2.39807e+02   -7.94197e-04    2.39808e+02    3.76645e-03    5.14755e-01\n",
      "             15    2.37480e+02   -8.10313e-04    2.37480e+02    4.41324e-03    5.09544e-01\n",
      "             16    2.35426e+02   -8.56318e-04    2.35426e+02    4.57290e-03    5.13627e-01\n",
      "             17    2.33545e+02   -8.96106e-04    2.33546e+02    4.23446e-03    5.09544e-01\n",
      "             18    2.31921e+02   -9.21361e-04    2.31922e+02    4.81507e-03    5.14621e-01\n",
      "             19    2.30509e+02   -8.92499e-04    2.30510e+02    3.98387e-03    5.16764e-01\n",
      "             20    2.29277e+02   -9.33537e-04    2.29278e+02    4.83201e-03    5.13243e-01\n",
      "             21    2.28177e+02   -9.10663e-04    2.28178e+02    3.81289e-03    5.15745e-01\n",
      "             22    2.27189e+02   -9.44717e-04    2.27190e+02    4.60704e-03    5.12212e-01\n",
      "             23    2.26403e+02   -9.29549e-04    2.26404e+02    4.30116e-03    5.15211e-01\n",
      "             24    2.25676e+02   -9.55086e-04    2.25677e+02    4.76272e-03    5.12716e-01\n",
      "             25    2.25067e+02   -9.83512e-04    2.25068e+02    4.30906e-03    5.16466e-01\n",
      "             26    2.24486e+02   -1.02811e-03    2.24487e+02    4.51377e-03    5.17528e-01\n",
      "             27    2.23948e+02   -1.03613e-03    2.23949e+02    4.48448e-03    5.08032e-01\n",
      "             28    2.23430e+02   -9.60090e-04    2.23431e+02    4.38630e-03    5.20130e-01\n",
      "             29    2.22982e+02   -1.00834e-03    2.22983e+02    4.85461e-03    5.13892e-01\n",
      "kl div: 0.00485461\n",
      "kl coeff: 0.0035156250000000005\n",
      "rollouts time: 8.561580181121826\n",
      "shuffle time: 0.0044400691986083984\n",
      "load time: 0.0014033317565917969\n",
      "sgd time: 18.22930335998535\n",
      "sgd examples/s: 2226.9638723063426\n",
      "total time so far: 394.70467734336853\n",
      "TrainingResult(experiment_id='aaf6071946ae492eb28236dfaaae1b3c', training_iteration=10, episode_reward_mean=200.0, episode_len_mean=199.0, info={'kl_divergence': 0.0048546069, 'kl_coefficient': 0.0035156250000000005, 'rollouts_time': 8.561580181121826, 'shuffle_time': 0.0044400691986083984, 'load_time': 0.0014033317565917969, 'sgd_time': 18.22930335998535, 'sample_throughput': 2226.9638723063426}, timesteps_this_iter=40596, timesteps_total=406251, time_this_iter_s=26.802711725234985, time_total_s=271.08203125)\n",
      "===> iteration 11\n",
      "total reward is  199.950980392\n",
      "trajectory length mean is  198.950980392\n",
      "timesteps: 40586\n",
      "Computing policy (iterations=30, stepsize=5e-05):\n",
      "           iter     total loss    policy loss        vf loss             kl        entropy\n",
      "              0    8.14938e+02    3.27172e-04    8.14937e+02    2.68112e-04    5.22488e-01\n",
      "              1    3.26836e+02    2.47851e-04    3.26835e+02    2.29217e-04    5.16723e-01\n",
      "              2    2.57921e+02    1.52516e-04    2.57921e+02    1.38286e-03    5.35240e-01\n",
      "              3    2.40811e+02    7.51027e-05    2.40811e+02    8.95829e-04    5.32291e-01\n",
      "              4    2.33652e+02   -4.27739e-05    2.33652e+02    2.11245e-03    5.41551e-01\n",
      "              5    2.29287e+02   -7.53673e-05    2.29287e+02    2.12619e-03    5.41407e-01\n",
      "              6    2.26032e+02   -1.43319e-04    2.26032e+02    2.75715e-03    5.45283e-01\n",
      "              7    2.23376e+02   -2.11738e-04    2.23376e+02    2.98618e-03    5.44185e-01\n",
      "              8    2.21208e+02   -2.26865e-04    2.21208e+02    2.54654e-03    5.38962e-01\n",
      "              9    2.19425e+02   -2.70924e-04    2.19425e+02    2.71065e-03    5.39487e-01\n",
      "             10    2.17955e+02   -2.95837e-04    2.17956e+02    2.31680e-03    5.38465e-01\n",
      "             11    2.16711e+02   -3.28645e-04    2.16711e+02    3.04867e-03    5.41672e-01\n",
      "             12    2.15679e+02   -3.07849e-04    2.15680e+02    3.55607e-03    5.36103e-01\n",
      "             13    2.14836e+02   -4.01953e-04    2.14836e+02    3.49521e-03    5.37091e-01\n",
      "             14    2.14138e+02   -4.57967e-04    2.14138e+02    3.15058e-03    5.33742e-01\n",
      "             15    2.13532e+02   -4.95669e-04    2.13532e+02    3.65320e-03    5.35784e-01\n",
      "             16    2.12995e+02   -5.03723e-04    2.12995e+02    3.55030e-03    5.33139e-01\n",
      "             17    2.12584e+02   -5.34099e-04    2.12584e+02    3.77279e-03    5.31157e-01\n",
      "             18    2.12177e+02   -6.00287e-04    2.12177e+02    4.31239e-03    5.33269e-01\n",
      "             19    2.11807e+02   -5.72455e-04    2.11807e+02    3.65501e-03    5.27804e-01\n",
      "             20    2.11486e+02   -6.09256e-04    2.11486e+02    4.23512e-03    5.26771e-01\n",
      "             21    2.11175e+02   -6.87087e-04    2.11175e+02    4.66245e-03    5.30859e-01\n",
      "             22    2.10903e+02   -6.41373e-04    2.10903e+02    3.92978e-03    5.24263e-01\n",
      "             23    2.10613e+02   -6.64839e-04    2.10614e+02    3.78319e-03    5.24868e-01\n",
      "             24    2.10364e+02   -6.78852e-04    2.10365e+02    4.76513e-03    5.22705e-01\n",
      "             25    2.10156e+02   -7.31447e-04    2.10157e+02    4.48634e-03    5.16253e-01\n",
      "             26    2.09937e+02   -8.09696e-04    2.09938e+02    4.89024e-03    5.26225e-01\n",
      "             27    2.09755e+02   -7.86310e-04    2.09756e+02    5.08129e-03    5.12812e-01\n",
      "             28    2.09572e+02   -8.12573e-04    2.09573e+02    4.45123e-03    5.24053e-01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             29    2.09413e+02   -7.72173e-04    2.09414e+02    4.46291e-03    5.14065e-01\n",
      "kl div: 0.00446291\n",
      "kl coeff: 0.0017578125000000003\n",
      "rollouts time: 8.559034824371338\n",
      "shuffle time: 0.004549980163574219\n",
      "load time: 0.0013918876647949219\n",
      "sgd time: 18.358441829681396\n",
      "sgd examples/s: 2210.7540703362815\n",
      "total time so far: 421.6331603527069\n",
      "TrainingResult(experiment_id='aaf6071946ae492eb28236dfaaae1b3c', training_iteration=11, episode_reward_mean=199.95098039215685, episode_len_mean=198.95098039215685, info={'kl_divergence': 0.0044629145, 'kl_coefficient': 0.0017578125000000003, 'rollouts_time': 8.559034824371338, 'shuffle_time': 0.004549980163574219, 'load_time': 0.0013918876647949219, 'sgd_time': 18.358441829681396, 'sample_throughput': 2210.7540703362815}, timesteps_this_iter=40586, timesteps_total=446837, time_this_iter_s=26.928181409835815, time_total_s=298.0102126598358)\n",
      "===> iteration 12\n",
      "total reward is  200.0\n",
      "trajectory length mean is  199.0\n",
      "timesteps: 40596\n",
      "Computing policy (iterations=30, stepsize=5e-05):\n",
      "           iter     total loss    policy loss        vf loss             kl        entropy\n",
      "              0    5.71975e+02    1.74982e-04    5.71975e+02    2.18393e-04    5.21663e-01\n",
      "              1    3.21464e+02   -7.17800e-05    3.21464e+02    9.06776e-04    5.30999e-01\n",
      "              2    2.82795e+02   -2.65577e-04    2.82795e+02    2.13694e-03    5.34886e-01\n",
      "              3    2.71734e+02   -3.13431e-04    2.71734e+02    2.15995e-03    5.30508e-01\n",
      "              4    2.66886e+02   -3.77261e-04    2.66886e+02    2.49757e-03    5.29601e-01\n",
      "              5    2.63661e+02   -5.43005e-04    2.63661e+02    2.77750e-03    5.27914e-01\n",
      "              6    2.61025e+02   -5.65192e-04    2.61025e+02    2.33849e-03    5.30534e-01\n",
      "              7    2.58691e+02   -6.77864e-04    2.58692e+02    3.11672e-03    5.21884e-01\n",
      "              8    2.56386e+02   -7.30134e-04    2.56386e+02    4.17774e-03    5.21805e-01\n",
      "              9    2.54012e+02   -7.05953e-04    2.54012e+02    3.75945e-03    5.17261e-01\n",
      "             10    2.51420e+02   -8.26186e-04    2.51421e+02    4.18550e-03    5.20470e-01\n",
      "             11    2.48710e+02   -8.86903e-04    2.48710e+02    3.77587e-03    5.21238e-01\n",
      "             12    2.46296e+02   -9.71181e-04    2.46296e+02    4.40496e-03    5.20719e-01\n",
      "             13    2.44251e+02   -9.99011e-04    2.44252e+02    4.54646e-03    5.13706e-01\n",
      "             14    2.42445e+02   -1.01646e-03    2.42446e+02    4.39791e-03    5.16487e-01\n",
      "             15    2.40851e+02   -1.01550e-03    2.40852e+02    4.26893e-03    5.16847e-01\n",
      "             16    2.39347e+02   -1.05491e-03    2.39348e+02    5.05176e-03    5.13195e-01\n",
      "             17    2.37958e+02   -1.14701e-03    2.37959e+02    4.69602e-03    5.16418e-01\n",
      "             18    2.36620e+02   -1.20237e-03    2.36621e+02    5.27280e-03    5.04658e-01\n",
      "             19    2.35386e+02   -1.19550e-03    2.35387e+02    4.66884e-03    5.11812e-01\n",
      "             20    2.34183e+02   -1.28858e-03    2.34184e+02    5.61213e-03    5.10943e-01\n",
      "             21    2.33128e+02   -1.28709e-03    2.33129e+02    4.83600e-03    5.07864e-01\n",
      "             22    2.32153e+02   -1.27489e-03    2.32154e+02    5.31648e-03    5.10346e-01\n",
      "             23    2.31273e+02   -1.34342e-03    2.31275e+02    5.37218e-03    5.09430e-01\n",
      "             24    2.30490e+02   -1.35764e-03    2.30492e+02    5.27585e-03    5.06765e-01\n",
      "             25    2.29788e+02   -1.36858e-03    2.29790e+02    5.26755e-03    5.06095e-01\n",
      "             26    2.29209e+02   -1.43927e-03    2.29211e+02    5.10094e-03    5.11062e-01\n",
      "             27    2.28696e+02   -1.42652e-03    2.28697e+02    6.10175e-03    5.01193e-01\n",
      "             28    2.28226e+02   -1.49449e-03    2.28228e+02    5.38418e-03    5.00606e-01\n",
      "             29    2.27821e+02   -1.51086e-03    2.27822e+02    6.12858e-03    5.02112e-01\n",
      "kl div: 0.00612858\n",
      "kl coeff: 0.0017578125000000003\n",
      "rollouts time: 8.664865255355835\n",
      "shuffle time: 0.004554271697998047\n",
      "load time: 0.0014224052429199219\n",
      "sgd time: 18.447234392166138\n",
      "sgd examples/s: 2200.655075822077\n",
      "total time so far: 448.75617694854736\n",
      "TrainingResult(experiment_id='aaf6071946ae492eb28236dfaaae1b3c', training_iteration=12, episode_reward_mean=200.0, episode_len_mean=199.0, info={'kl_divergence': 0.006128578, 'kl_coefficient': 0.0017578125000000003, 'rollouts_time': 8.664865255355835, 'shuffle_time': 0.004554271697998047, 'load_time': 0.0014224052429199219, 'sgd_time': 18.447234392166138, 'sample_throughput': 2200.655075822077}, timesteps_this_iter=40596, timesteps_total=487433, time_this_iter_s=27.122836112976074, time_total_s=325.1330487728119)\n",
      "===> iteration 13\n",
      "total reward is  199.725490196\n",
      "trajectory length mean is  198.725490196\n",
      "timesteps: 40540\n",
      "Computing policy (iterations=30, stepsize=5e-05):\n",
      "           iter     total loss    policy loss        vf loss             kl        entropy\n",
      "              0    7.60206e+02    2.85867e-04    7.60205e+02    3.88154e-04    5.13813e-01\n",
      "              1    3.01331e+02    1.00610e-04    3.01331e+02    1.86205e-04    5.18823e-01\n",
      "              2    2.62179e+02    3.74638e-05    2.62179e+02    8.98053e-04    5.29388e-01\n",
      "              3    2.51103e+02   -4.03052e-05    2.51103e+02    1.34303e-03    5.26920e-01\n",
      "              4    2.45893e+02   -1.58728e-04    2.45893e+02    1.78092e-03    5.28223e-01\n",
      "              5    2.42772e+02   -2.13955e-04    2.42772e+02    2.98305e-03    5.25748e-01\n",
      "              6    2.40675e+02   -2.97058e-04    2.40675e+02    2.86997e-03    5.28625e-01\n",
      "              7    2.39116e+02   -3.26299e-04    2.39116e+02    2.40876e-03    5.21911e-01\n",
      "              8    2.37840e+02   -3.43922e-04    2.37841e+02    2.96725e-03    5.25443e-01\n",
      "              9    2.36727e+02   -4.01068e-04    2.36728e+02    3.44136e-03    5.22345e-01\n",
      "             10    2.35766e+02   -3.87088e-04    2.35767e+02    2.88134e-03    5.22010e-01\n",
      "             11    2.34913e+02   -4.80902e-04    2.34914e+02    2.81221e-03    5.27032e-01\n",
      "             12    2.34107e+02   -4.50798e-04    2.34107e+02    2.45707e-03    5.19626e-01\n",
      "             13    2.33453e+02   -4.81702e-04    2.33453e+02    2.52405e-03    5.27506e-01\n",
      "             14    2.32806e+02   -5.54368e-04    2.32806e+02    2.67523e-03    5.26440e-01\n",
      "             15    2.32244e+02   -5.35413e-04    2.32245e+02    2.43914e-03    5.18014e-01\n",
      "             16    2.31707e+02   -6.15476e-04    2.31708e+02    2.53439e-03    5.22718e-01\n",
      "             17    2.31191e+02   -6.48483e-04    2.31192e+02    2.71824e-03    5.21521e-01\n",
      "             18    2.30755e+02   -6.88236e-04    2.30755e+02    2.42572e-03    5.24568e-01\n",
      "             19    2.30311e+02   -6.73906e-04    2.30312e+02    2.11867e-03    5.15123e-01\n",
      "             20    2.29946e+02   -7.35545e-04    2.29946e+02    2.39452e-03    5.19971e-01\n",
      "             21    2.29592e+02   -7.90705e-04    2.29593e+02    2.87768e-03    5.23841e-01\n",
      "             22    2.29274e+02   -7.45267e-04    2.29275e+02    3.07021e-03    5.20664e-01\n",
      "             23    2.28968e+02   -7.66346e-04    2.28968e+02    1.90252e-03    5.20074e-01\n",
      "             24    2.28687e+02   -8.45444e-04    2.28688e+02    2.45849e-03    5.21108e-01\n",
      "             25    2.28422e+02   -8.34765e-04    2.28423e+02    2.41921e-03    5.22358e-01\n",
      "             26    2.28164e+02   -8.87446e-04    2.28165e+02    2.38211e-03    5.22152e-01\n",
      "             27    2.27907e+02   -9.26155e-04    2.27908e+02    2.45575e-03    5.22380e-01\n",
      "             28    2.27699e+02   -9.24088e-04    2.27700e+02    2.18020e-03    5.19596e-01\n",
      "             29    2.27471e+02   -1.03929e-03    2.27472e+02    2.24740e-03    5.19944e-01\n",
      "kl div: 0.0022474\n",
      "kl coeff: 0.0008789062500000001\n",
      "rollouts time: 8.691868543624878\n",
      "shuffle time: 0.005131721496582031\n",
      "load time: 0.0013933181762695312\n",
      "sgd time: 17.32356572151184\n",
      "sgd examples/s: 2340.1648743514015\n",
      "total time so far: 474.78477358818054\n",
      "TrainingResult(experiment_id='aaf6071946ae492eb28236dfaaae1b3c', training_iteration=13, episode_reward_mean=199.72549019607843, episode_len_mean=198.72549019607843, info={'kl_divergence': 0.0022474017, 'kl_coefficient': 0.0008789062500000001, 'rollouts_time': 8.691868543624878, 'shuffle_time': 0.005131721496582031, 'load_time': 0.0013933181762695312, 'sgd_time': 17.32356572151184, 'sample_throughput': 2340.1648743514015}, timesteps_this_iter=40540, timesteps_total=527973, time_this_iter_s=26.02842617034912, time_total_s=351.161474943161)\n",
      "===> iteration 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total reward is  198.004901961\n",
      "trajectory length mean is  197.004901961\n",
      "timesteps: 40189\n",
      "Computing policy (iterations=30, stepsize=5e-05):\n",
      "           iter     total loss    policy loss        vf loss             kl        entropy\n",
      "              0    5.95610e+02   -8.30503e-04    5.95611e+02    7.49417e-04    5.12182e-01\n",
      "              1    3.27245e+02   -1.11166e-03    3.27246e+02    1.57430e-03    5.02363e-01\n",
      "              2    2.78624e+02   -1.33474e-03    2.78625e+02    2.85658e-03    4.95744e-01\n",
      "              3    2.61087e+02   -1.47280e-03    2.61088e+02    4.10106e-03    4.92422e-01\n",
      "              4    2.53010e+02   -1.56411e-03    2.53012e+02    4.20282e-03    4.92715e-01\n",
      "              5    2.48571e+02   -1.61524e-03    2.48573e+02    3.88703e-03    5.01291e-01\n",
      "              6    2.45924e+02   -1.71139e-03    2.45926e+02    4.58175e-03    4.94469e-01\n",
      "              7    2.44157e+02   -1.75729e-03    2.44158e+02    4.92590e-03    4.96527e-01\n",
      "              8    2.42899e+02   -1.76921e-03    2.42901e+02    4.63644e-03    4.97879e-01\n",
      "              9    2.41964e+02   -1.73458e-03    2.41965e+02    4.22585e-03    4.95898e-01\n",
      "             10    2.41180e+02   -1.82700e-03    2.41181e+02    5.43738e-03    4.92911e-01\n",
      "             11    2.40493e+02   -1.84519e-03    2.40495e+02    4.39430e-03    4.97418e-01\n",
      "             12    2.39885e+02   -1.87480e-03    2.39887e+02    4.29509e-03    4.94959e-01\n",
      "             13    2.39372e+02   -1.89403e-03    2.39374e+02    5.38791e-03    4.93350e-01\n",
      "             14    2.38873e+02   -1.88916e-03    2.38875e+02    4.97111e-03    4.97093e-01\n",
      "             15    2.38435e+02   -1.93696e-03    2.38437e+02    5.01421e-03    4.95823e-01\n",
      "             16    2.38004e+02   -1.91291e-03    2.38006e+02    5.66656e-03    4.92011e-01\n",
      "             17    2.37604e+02   -1.97062e-03    2.37606e+02    5.01028e-03    4.93982e-01\n",
      "             18    2.37258e+02   -2.00312e-03    2.37260e+02    4.94069e-03    4.97086e-01\n",
      "             19    2.36944e+02   -2.02288e-03    2.36946e+02    4.37443e-03    4.97809e-01\n",
      "             20    2.36628e+02   -2.02505e-03    2.36630e+02    4.77636e-03    4.94179e-01\n",
      "             21    2.36374e+02   -2.06921e-03    2.36376e+02    5.40356e-03    4.95281e-01\n",
      "             22    2.36092e+02   -2.06129e-03    2.36094e+02    4.95945e-03    4.94789e-01\n",
      "             23    2.35867e+02   -2.03733e-03    2.35869e+02    3.59576e-03    4.97226e-01\n",
      "             24    2.35623e+02   -2.07767e-03    2.35625e+02    4.18456e-03    4.96073e-01\n",
      "             25    2.35371e+02   -2.11925e-03    2.35374e+02    5.46591e-03    4.94283e-01\n",
      "             26    2.35187e+02   -2.10741e-03    2.35189e+02    3.93386e-03    4.97553e-01\n",
      "             27    2.34998e+02   -2.10657e-03    2.35000e+02    4.64803e-03    4.97341e-01\n",
      "             28    2.34791e+02   -2.09888e-03    2.34793e+02    4.38350e-03    4.96893e-01\n",
      "             29    2.34645e+02   -2.11694e-03    2.34647e+02    4.97602e-03    4.97036e-01\n",
      "kl div: 0.00497602\n",
      "kl coeff: 0.00043945312500000007\n",
      "rollouts time: 8.490467071533203\n",
      "shuffle time: 0.005707263946533203\n",
      "load time: 0.0015993118286132812\n",
      "sgd time: 17.850416898727417\n",
      "sgd examples/s: 2251.432010132219\n",
      "total time so far: 501.13920187950134\n",
      "TrainingResult(experiment_id='aaf6071946ae492eb28236dfaaae1b3c', training_iteration=14, episode_reward_mean=198.00490196078431, episode_len_mean=197.00490196078431, info={'kl_divergence': 0.0049760207, 'kl_coefficient': 0.00043945312500000007, 'rollouts_time': 8.490467071533203, 'shuffle_time': 0.005707263946533203, 'load_time': 0.0015993118286132812, 'sgd_time': 17.850416898727417, 'sample_throughput': 2251.432010132219}, timesteps_this_iter=40189, timesteps_total=568162, time_this_iter_s=26.35412883758545, time_total_s=377.51560378074646)\n",
      "===> iteration 15\n",
      "total reward is  199.705882353\n",
      "trajectory length mean is  198.705882353\n",
      "timesteps: 40536\n",
      "Computing policy (iterations=30, stepsize=5e-05):\n",
      "           iter     total loss    policy loss        vf loss             kl        entropy\n",
      "              0    9.05917e+02    3.23460e-04    9.05916e+02    6.87424e-04    5.07254e-01\n",
      "              1    3.28431e+02    9.71043e-05    3.28431e+02    1.62175e-03    5.21145e-01\n",
      "              2    2.73273e+02   -9.04304e-05    2.73273e+02    2.59776e-03    5.31893e-01\n",
      "              3    2.59517e+02   -3.41973e-04    2.59518e+02    2.50971e-03    5.30780e-01\n",
      "              4    2.54313e+02   -9.61311e-05    2.54313e+02    2.23483e-03    5.27357e-01\n",
      "              5    2.51581e+02   -3.40888e-04    2.51582e+02    3.60739e-03    5.33650e-01\n",
      "              6    2.49784e+02   -3.48635e-04    2.49784e+02    3.40033e-03    5.34174e-01\n",
      "              7    2.48420e+02   -4.41024e-04    2.48421e+02    4.37104e-03    5.35362e-01\n",
      "              8    2.47327e+02   -3.86875e-04    2.47328e+02    3.87242e-03    5.30116e-01\n",
      "              9    2.46367e+02   -4.79074e-04    2.46368e+02    4.49225e-03    5.33558e-01\n",
      "             10    2.45505e+02   -5.38276e-04    2.45505e+02    4.78216e-03    5.30849e-01\n",
      "             11    2.44745e+02   -6.67607e-04    2.44745e+02    5.21374e-03    5.32802e-01\n",
      "             12    2.44019e+02   -6.21551e-04    2.44019e+02    5.39566e-03    5.33829e-01\n",
      "             13    2.43359e+02   -6.06494e-04    2.43360e+02    3.48525e-03    5.22102e-01\n",
      "             14    2.42802e+02   -6.94774e-04    2.42803e+02    4.70492e-03    5.30000e-01\n",
      "             15    2.42308e+02   -6.58597e-04    2.42308e+02    5.46215e-03    5.32077e-01\n",
      "             16    2.41844e+02   -7.44262e-04    2.41844e+02    5.21346e-03    5.30040e-01\n",
      "             17    2.41442e+02   -6.57522e-04    2.41443e+02    3.47679e-03    5.24419e-01\n",
      "             18    2.41097e+02   -7.77576e-04    2.41098e+02    4.90407e-03    5.30273e-01\n",
      "             19    2.40758e+02   -7.64505e-04    2.40759e+02    4.64095e-03    5.27884e-01\n",
      "             20    2.40465e+02   -8.32694e-04    2.40466e+02    5.19343e-03    5.31063e-01\n",
      "             21    2.40200e+02   -8.03672e-04    2.40201e+02    5.17675e-03    5.29555e-01\n",
      "             22    2.39959e+02   -8.15674e-04    2.39959e+02    4.65593e-03    5.27617e-01\n",
      "             23    2.39714e+02   -8.21200e-04    2.39715e+02    4.91649e-03    5.28662e-01\n",
      "             24    2.39484e+02   -9.04589e-04    2.39485e+02    5.06907e-03    5.29912e-01\n",
      "             25    2.39287e+02   -9.00231e-04    2.39288e+02    4.92708e-03    5.28869e-01\n",
      "             26    2.39088e+02   -9.19112e-04    2.39089e+02    4.69860e-03    5.27261e-01\n",
      "             27    2.38899e+02   -8.88208e-04    2.38899e+02    4.75326e-03    5.29630e-01\n",
      "             28    2.38715e+02   -9.30944e-04    2.38715e+02    4.77306e-03    5.25719e-01\n",
      "             29    2.38539e+02   -8.95707e-04    2.38540e+02    4.93756e-03    5.28215e-01\n",
      "kl div: 0.00493756\n",
      "kl coeff: 0.00021972656250000003\n",
      "rollouts time: 8.479031801223755\n",
      "shuffle time: 0.005246162414550781\n",
      "load time: 0.0016286373138427734\n",
      "sgd time: 18.106011390686035\n",
      "sgd examples/s: 2238.814453682065\n",
      "total time so far: 527.736745595932\n",
      "TrainingResult(experiment_id='aaf6071946ae492eb28236dfaaae1b3c', training_iteration=15, episode_reward_mean=199.70588235294119, episode_len_mean=198.70588235294119, info={'kl_divergence': 0.0049375622, 'kl_coefficient': 0.00021972656250000003, 'rollouts_time': 8.479031801223755, 'shuffle_time': 0.005246162414550781, 'load_time': 0.0016286373138427734, 'sgd_time': 18.106011390686035, 'sample_throughput': 2238.814453682065}, timesteps_this_iter=40536, timesteps_total=608698, time_this_iter_s=26.59734582901001, time_total_s=404.11294960975647)\n",
      "===> iteration 16\n",
      "total reward is  197.647058824\n",
      "trajectory length mean is  196.647058824\n",
      "timesteps: 40116\n",
      "Computing policy (iterations=30, stepsize=5e-05):\n",
      "           iter     total loss    policy loss        vf loss             kl        entropy\n",
      "              0    5.55623e+02   -8.62326e-04    5.55624e+02    1.77934e-03    5.07682e-01\n",
      "              1    3.00624e+02   -1.74931e-03    3.00626e+02    5.75620e-03    5.04587e-01\n",
      "              2    2.73018e+02   -1.84630e-03    2.73020e+02    6.37616e-03    5.00053e-01\n",
      "              3    2.64935e+02   -2.00667e-03    2.64937e+02    6.20049e-03    5.02573e-01\n",
      "              4    2.61043e+02   -2.07252e-03    2.61045e+02    6.10227e-03    4.99884e-01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              5    2.58458e+02   -2.17826e-03    2.58460e+02    6.86491e-03    4.97065e-01\n",
      "              6    2.56513e+02   -2.25898e-03    2.56515e+02    6.82112e-03    4.98918e-01\n",
      "              7    2.54964e+02   -2.24479e-03    2.54966e+02    6.72969e-03    5.01591e-01\n",
      "              8    2.53627e+02   -2.31962e-03    2.53629e+02    6.88276e-03    4.98092e-01\n",
      "              9    2.52378e+02   -2.44720e-03    2.52381e+02    6.72508e-03    4.96625e-01\n",
      "             10    2.51195e+02   -2.47830e-03    2.51197e+02    7.64064e-03    4.96769e-01\n",
      "             11    2.50083e+02   -2.41569e-03    2.50086e+02    6.86974e-03    4.95680e-01\n",
      "             12    2.48984e+02   -2.51533e-03    2.48987e+02    7.38318e-03    4.95757e-01\n",
      "             13    2.47886e+02   -2.55983e-03    2.47888e+02    7.29028e-03    4.98351e-01\n",
      "             14    2.46816e+02   -2.68206e-03    2.46819e+02    7.47374e-03    4.98838e-01\n",
      "             15    2.45812e+02   -2.62668e-03    2.45815e+02    7.43878e-03    4.96720e-01\n",
      "             16    2.44855e+02   -2.60769e-03    2.44858e+02    7.35152e-03    4.94211e-01\n",
      "             17    2.43835e+02   -2.74329e-03    2.43838e+02    7.34392e-03    4.95820e-01\n",
      "             18    2.42854e+02   -2.73245e-03    2.42857e+02    7.62642e-03    4.94890e-01\n",
      "             19    2.41865e+02   -2.79258e-03    2.41868e+02    7.59440e-03    4.97086e-01\n",
      "             20    2.40856e+02   -2.81978e-03    2.40858e+02    7.52048e-03    4.92830e-01\n",
      "             21    2.39924e+02   -2.85741e-03    2.39926e+02    7.52797e-03    4.99774e-01\n",
      "             22    2.39006e+02   -2.85539e-03    2.39009e+02    7.36742e-03    4.96297e-01\n",
      "             23    2.38183e+02   -2.87176e-03    2.38186e+02    7.72869e-03    4.95942e-01\n",
      "             24    2.37409e+02   -2.83831e-03    2.37411e+02    7.71112e-03    4.94583e-01\n",
      "             25    2.36697e+02   -2.87885e-03    2.36700e+02    7.52642e-03    4.98028e-01\n",
      "             26    2.36068e+02   -2.92778e-03    2.36071e+02    7.73712e-03    4.95223e-01\n",
      "             27    2.35460e+02   -2.93538e-03    2.35463e+02    7.71843e-03    4.92505e-01\n",
      "             28    2.34932e+02   -2.99006e-03    2.34935e+02    7.87747e-03    4.96065e-01\n",
      "             29    2.34425e+02   -2.99106e-03    2.34428e+02    7.76970e-03    4.96991e-01\n",
      "kl div: 0.0077697\n",
      "kl coeff: 0.00021972656250000003\n",
      "rollouts time: 8.36794924736023\n",
      "shuffle time: 0.004869222640991211\n",
      "load time: 0.0015730857849121094\n",
      "sgd time: 17.995385885238647\n",
      "sgd examples/s: 2229.2381089147175\n",
      "total time so far: 554.1122817993164\n",
      "TrainingResult(experiment_id='aaf6071946ae492eb28236dfaaae1b3c', training_iteration=16, episode_reward_mean=197.64705882352942, episode_len_mean=196.64705882352942, info={'kl_divergence': 0.0077696987, 'kl_coefficient': 0.00021972656250000003, 'rollouts_time': 8.36794924736023, 'shuffle_time': 0.004869222640991211, 'load_time': 0.0015730857849121094, 'sgd_time': 17.995385885238647, 'sample_throughput': 2229.2381089147175}, timesteps_this_iter=40116, timesteps_total=648814, time_this_iter_s=26.37532615661621, time_total_s=430.4882757663727)\n",
      "===> iteration 17\n",
      "total reward is  199.789215686\n",
      "trajectory length mean is  198.789215686\n",
      "timesteps: 40553\n",
      "Computing policy (iterations=30, stepsize=5e-05):\n",
      "           iter     total loss    policy loss        vf loss             kl        entropy\n",
      "              0    8.83731e+02    1.60611e-04    8.83731e+02    2.06399e-04    4.93098e-01\n",
      "              1    3.17747e+02   -1.55136e-04    3.17747e+02    9.26901e-04    4.81903e-01\n",
      "              2    2.74168e+02   -4.83335e-04    2.74168e+02    2.70600e-03    4.70014e-01\n",
      "              3    2.67415e+02   -5.65855e-04    2.67415e+02    2.80028e-03    4.76462e-01\n",
      "              4    2.65050e+02   -6.45631e-04    2.65050e+02    3.69824e-03    4.81992e-01\n",
      "              5    2.63493e+02   -7.25986e-04    2.63493e+02    3.73346e-03    4.72340e-01\n",
      "              6    2.62164e+02   -7.47405e-04    2.62165e+02    3.66659e-03    4.73376e-01\n",
      "              7    2.60772e+02   -8.80421e-04    2.60773e+02    4.44182e-03    4.72538e-01\n",
      "              8    2.59113e+02   -8.72724e-04    2.59113e+02    4.06910e-03    4.76984e-01\n",
      "              9    2.57719e+02   -9.36462e-04    2.57720e+02    4.36816e-03    4.75302e-01\n",
      "             10    2.56692e+02   -9.33485e-04    2.56693e+02    3.90938e-03    4.83652e-01\n",
      "             11    2.55868e+02   -9.91992e-04    2.55869e+02    4.68290e-03    4.77631e-01\n",
      "             12    2.55135e+02   -1.02783e-03    2.55136e+02    4.59126e-03    4.77408e-01\n",
      "             13    2.54510e+02   -1.10250e-03    2.54511e+02    4.19885e-03    4.70603e-01\n",
      "             14    2.53940e+02   -1.06904e-03    2.53941e+02    4.55782e-03    4.79532e-01\n",
      "             15    2.53435e+02   -1.11934e-03    2.53436e+02    4.62321e-03    4.79668e-01\n",
      "             16    2.52993e+02   -1.14280e-03    2.52994e+02    4.33985e-03    4.72060e-01\n",
      "             17    2.52614e+02   -1.16124e-03    2.52615e+02    4.86571e-03    4.78201e-01\n",
      "             18    2.52263e+02   -1.13930e-03    2.52264e+02    4.47037e-03    4.77786e-01\n",
      "             19    2.51975e+02   -1.19912e-03    2.51976e+02    4.90157e-03    4.72651e-01\n",
      "             20    2.51704e+02   -1.24750e-03    2.51705e+02    4.23401e-03    4.73985e-01\n",
      "             21    2.51477e+02   -1.27979e-03    2.51478e+02    4.78964e-03    4.78130e-01\n",
      "             22    2.51283e+02   -1.25088e-03    2.51285e+02    4.59330e-03    4.68942e-01\n",
      "             23    2.51104e+02   -1.28223e-03    2.51105e+02    4.54278e-03    4.75958e-01\n",
      "             24    2.50949e+02   -1.30280e-03    2.50950e+02    4.57745e-03    4.70258e-01\n",
      "             25    2.50800e+02   -1.34259e-03    2.50801e+02    4.37394e-03    4.79171e-01\n",
      "             26    2.50683e+02   -1.39464e-03    2.50685e+02    4.62882e-03    4.72968e-01\n",
      "             27    2.50527e+02   -1.41194e-03    2.50529e+02    4.58818e-03    4.70026e-01\n",
      "             28    2.50416e+02   -1.36134e-03    2.50417e+02    4.90517e-03    4.75559e-01\n",
      "             29    2.50299e+02   -1.42790e-03    2.50300e+02    4.67995e-03    4.74517e-01\n",
      "kl div: 0.00467995\n",
      "kl coeff: 0.00010986328125000002\n",
      "rollouts time: 8.75183391571045\n",
      "shuffle time: 0.005896568298339844\n",
      "load time: 0.0018925666809082031\n",
      "sgd time: 20.009679794311523\n",
      "sgd examples/s: 2026.6691129924359\n",
      "total time so far: 582.890082359314\n",
      "TrainingResult(experiment_id='aaf6071946ae492eb28236dfaaae1b3c', training_iteration=17, episode_reward_mean=199.7892156862745, episode_len_mean=198.7892156862745, info={'kl_divergence': 0.00467995, 'kl_coefficient': 0.00010986328125000002, 'rollouts_time': 8.75183391571045, 'shuffle_time': 0.005896568298339844, 'load_time': 0.0018925666809082031, 'sgd_time': 20.009679794311523, 'sample_throughput': 2026.6691129924359}, timesteps_this_iter=40553, timesteps_total=689367, time_this_iter_s=28.77779531478882, time_total_s=459.2660710811615)\n",
      "===> iteration 18\n",
      "total reward is  200.0\n",
      "trajectory length mean is  199.0\n",
      "timesteps: 40596\n",
      "Computing policy (iterations=30, stepsize=5e-05):\n",
      "           iter     total loss    policy loss        vf loss             kl        entropy\n",
      "              0    6.45200e+02   -1.59990e-04    6.45201e+02    4.05957e-04    4.87270e-01\n",
      "              1    2.91191e+02   -7.03026e-04    2.91192e+02    2.27949e-03    5.07340e-01\n",
      "              2    2.66385e+02   -6.01929e-04    2.66386e+02    2.09990e-03    5.02443e-01\n",
      "              3    2.62118e+02   -7.63289e-04    2.62119e+02    2.36958e-03    5.03092e-01\n",
      "              4    2.60153e+02   -7.39242e-04    2.60154e+02    1.96047e-03    4.97185e-01\n",
      "              5    2.58715e+02   -8.49773e-04    2.58716e+02    2.84529e-03    5.04391e-01\n",
      "              6    2.57457e+02   -8.79180e-04    2.57458e+02    2.43192e-03    5.02975e-01\n",
      "              7    2.56309e+02   -9.36017e-04    2.56309e+02    2.66527e-03    5.02792e-01\n",
      "              8    2.55201e+02   -9.68587e-04    2.55202e+02    2.78782e-03    5.04229e-01\n",
      "              9    2.54155e+02   -1.01955e-03    2.54156e+02    2.99320e-03    5.01495e-01\n",
      "             10    2.53210e+02   -1.08917e-03    2.53211e+02    3.09916e-03    5.05198e-01\n",
      "             11    2.52288e+02   -1.12192e-03    2.52289e+02    3.16550e-03    4.95417e-01\n",
      "             12    2.51489e+02   -1.11980e-03    2.51491e+02    3.18038e-03    5.05599e-01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             13    2.50829e+02   -1.12666e-03    2.50831e+02    3.10541e-03    5.04706e-01\n",
      "             14    2.50215e+02   -1.14055e-03    2.50216e+02    3.13577e-03    5.01165e-01\n",
      "             15    2.49672e+02   -1.20289e-03    2.49673e+02    3.26135e-03    5.02926e-01\n",
      "             16    2.49239e+02   -1.27091e-03    2.49240e+02    3.28408e-03    5.03903e-01\n",
      "             17    2.48837e+02   -1.23491e-03    2.48838e+02    3.49777e-03    5.02219e-01\n",
      "             18    2.48524e+02   -1.31065e-03    2.48525e+02    3.37488e-03    5.04479e-01\n",
      "             19    2.48189e+02   -1.28614e-03    2.48190e+02    3.23664e-03    4.99667e-01\n",
      "             20    2.47960e+02   -1.34871e-03    2.47961e+02    3.43908e-03    5.01938e-01\n",
      "             21    2.47721e+02   -1.43755e-03    2.47722e+02    3.63670e-03    5.04319e-01\n",
      "             22    2.47525e+02   -1.40977e-03    2.47526e+02    3.61360e-03    5.04943e-01\n",
      "             23    2.47343e+02   -1.51165e-03    2.47344e+02    3.74736e-03    5.04569e-01\n",
      "             24    2.47157e+02   -1.40960e-03    2.47159e+02    3.35708e-03    5.01290e-01\n",
      "             25    2.47013e+02   -1.40321e-03    2.47014e+02    3.69550e-03    5.01717e-01\n",
      "             26    2.46872e+02   -1.50893e-03    2.46873e+02    3.56418e-03    4.96990e-01\n",
      "             27    2.46756e+02   -1.41487e-03    2.46758e+02    3.43914e-03    4.96735e-01\n",
      "             28    2.46617e+02   -1.52301e-03    2.46619e+02    3.75511e-03    5.04548e-01\n",
      "             29    2.46516e+02   -1.57423e-03    2.46518e+02    3.82504e-03    5.04145e-01\n",
      "kl div: 0.00382504\n",
      "kl coeff: 5.493164062500001e-05\n",
      "rollouts time: 10.406408786773682\n",
      "shuffle time: 0.0054666996002197266\n",
      "load time: 0.001577615737915039\n",
      "sgd time: 19.817981719970703\n",
      "sgd examples/s: 2048.4427008574316\n",
      "total time so far: 613.1311409473419\n",
      "TrainingResult(experiment_id='aaf6071946ae492eb28236dfaaae1b3c', training_iteration=18, episode_reward_mean=200.0, episode_len_mean=199.0, info={'kl_divergence': 0.0038250384, 'kl_coefficient': 5.493164062500001e-05, 'rollouts_time': 10.406408786773682, 'shuffle_time': 0.0054666996002197266, 'load_time': 0.001577615737915039, 'sgd_time': 19.817981719970703, 'sample_throughput': 2048.4427008574316}, timesteps_this_iter=40596, timesteps_total=729963, time_this_iter_s=30.2405526638031, time_total_s=489.5066237449646)\n",
      "===> iteration 19\n",
      "total reward is  199.862745098\n",
      "trajectory length mean is  198.862745098\n",
      "timesteps: 40568\n",
      "Computing policy (iterations=30, stepsize=5e-05):\n",
      "           iter     total loss    policy loss        vf loss             kl        entropy\n",
      "              0    9.67855e+02    1.57849e-04    9.67855e+02    3.46731e-04    4.92516e-01\n",
      "              1    3.04939e+02   -6.51853e-05    3.04939e+02    3.95502e-04    4.92029e-01\n",
      "              2    2.70790e+02   -2.73359e-04    2.70791e+02    7.30176e-04    4.88937e-01\n",
      "              3    2.64449e+02   -4.39247e-04    2.64449e+02    3.33831e-03    4.86308e-01\n",
      "              4    2.61004e+02   -5.22137e-04    2.61004e+02    2.94948e-03    4.70735e-01\n",
      "              5    2.58325e+02   -5.91870e-04    2.58325e+02    3.23907e-03    4.86340e-01\n",
      "              6    2.56088e+02   -7.63333e-04    2.56089e+02    4.22530e-03    4.82313e-01\n",
      "              7    2.54211e+02   -7.10537e-04    2.54212e+02    2.94301e-03    4.78354e-01\n",
      "              8    2.52650e+02   -8.65166e-04    2.52651e+02    3.39712e-03    4.74287e-01\n",
      "              9    2.51397e+02   -9.10543e-04    2.51398e+02    3.06670e-03    4.75471e-01\n",
      "             10    2.50358e+02   -9.35819e-04    2.50359e+02    3.54261e-03    4.82258e-01\n",
      "             11    2.49500e+02   -1.03210e-03    2.49501e+02    4.11571e-03    4.85299e-01\n",
      "             12    2.48804e+02   -1.13992e-03    2.48805e+02    4.10757e-03    4.74726e-01\n",
      "             13    2.48199e+02   -1.17221e-03    2.48201e+02    3.53588e-03    4.85175e-01\n",
      "             14    2.47677e+02   -1.15880e-03    2.47678e+02    3.56443e-03    4.75943e-01\n",
      "             15    2.47179e+02   -1.25918e-03    2.47180e+02    3.60290e-03    4.78446e-01\n",
      "             16    2.46790e+02   -1.31557e-03    2.46791e+02    3.74660e-03    4.76170e-01\n",
      "             17    2.46427e+02   -1.35052e-03    2.46429e+02    3.94899e-03    4.84765e-01\n",
      "             18    2.46100e+02   -1.33809e-03    2.46101e+02    3.36363e-03    4.77363e-01\n",
      "             19    2.45798e+02   -1.38769e-03    2.45799e+02    3.77286e-03    4.79433e-01\n",
      "             20    2.45535e+02   -1.44219e-03    2.45536e+02    4.13029e-03    4.80130e-01\n",
      "             21    2.45280e+02   -1.49986e-03    2.45281e+02    3.81851e-03    4.80993e-01\n",
      "             22    2.45056e+02   -1.49418e-03    2.45057e+02    3.47764e-03    4.79379e-01\n",
      "             23    2.44834e+02   -1.58029e-03    2.44836e+02    3.89343e-03    4.81692e-01\n",
      "             24    2.44670e+02   -1.57079e-03    2.44672e+02    3.89233e-03    4.79257e-01\n",
      "             25    2.44473e+02   -1.65610e-03    2.44475e+02    4.13149e-03    4.82210e-01\n",
      "             26    2.44285e+02   -1.69462e-03    2.44287e+02    4.05527e-03    4.83764e-01\n",
      "             27    2.44139e+02   -1.70251e-03    2.44141e+02    3.57423e-03    4.82064e-01\n",
      "             28    2.43963e+02   -1.68011e-03    2.43965e+02    4.17335e-03    4.76160e-01\n",
      "             29    2.43800e+02   -1.70120e-03    2.43801e+02    3.93208e-03    4.80943e-01\n",
      "kl div: 0.00393208\n",
      "kl coeff: 2.7465820312500004e-05\n",
      "rollouts time: 10.190634727478027\n",
      "shuffle time: 0.005513429641723633\n",
      "load time: 0.0016789436340332031\n",
      "sgd time: 19.126657724380493\n",
      "sgd examples/s: 2121.0187678680795\n",
      "total time so far: 642.4649188518524\n",
      "TrainingResult(experiment_id='aaf6071946ae492eb28236dfaaae1b3c', training_iteration=19, episode_reward_mean=199.86274509803923, episode_len_mean=198.86274509803923, info={'kl_divergence': 0.0039320807, 'kl_coefficient': 2.7465820312500004e-05, 'rollouts_time': 10.190634727478027, 'shuffle_time': 0.005513429641723633, 'load_time': 0.0016789436340332031, 'sgd_time': 19.126657724380493, 'sample_throughput': 2121.0187678680795}, timesteps_this_iter=40568, timesteps_total=770531, time_this_iter_s=29.333518505096436, time_total_s=518.840142250061)\n",
      "===> iteration 20\n",
      "total reward is  199.303921569\n",
      "trajectory length mean is  198.303921569\n",
      "timesteps: 40454\n",
      "Computing policy (iterations=30, stepsize=5e-05):\n",
      "           iter     total loss    policy loss        vf loss             kl        entropy\n",
      "              0    6.20825e+02    8.59533e-05    6.20825e+02    6.37669e-04    4.91389e-01\n",
      "              1    2.79260e+02   -2.55613e-04    2.79260e+02    2.00912e-03    4.95995e-01\n",
      "              2    2.61785e+02   -4.52477e-04    2.61785e+02    2.64685e-03    4.93865e-01\n",
      "              3    2.59147e+02   -5.18052e-04    2.59148e+02    2.95631e-03    4.95299e-01\n",
      "              4    2.58056e+02   -5.82308e-04    2.58057e+02    2.28358e-03    4.74714e-01\n",
      "              5    2.57289e+02   -6.55100e-04    2.57290e+02    2.92740e-03    4.82885e-01\n",
      "              6    2.56602e+02   -6.83973e-04    2.56603e+02    3.19166e-03    4.84579e-01\n",
      "              7    2.55986e+02   -7.04650e-04    2.55986e+02    3.42605e-03    4.82962e-01\n",
      "              8    2.55423e+02   -7.75645e-04    2.55423e+02    3.49961e-03    4.79412e-01\n",
      "              9    2.54928e+02   -8.18464e-04    2.54929e+02    3.76280e-03    4.83116e-01\n",
      "             10    2.54447e+02   -7.85667e-04    2.54447e+02    3.28644e-03    4.79551e-01\n",
      "             11    2.54005e+02   -8.82469e-04    2.54006e+02    3.74213e-03    4.83824e-01\n",
      "             12    2.53599e+02   -8.67111e-04    2.53600e+02    3.78590e-03    4.83660e-01\n",
      "             13    2.53236e+02   -9.30593e-04    2.53237e+02    3.59394e-03    4.80516e-01\n",
      "             14    2.52903e+02   -1.03783e-03    2.52904e+02    3.71541e-03    4.81645e-01\n",
      "             15    2.52627e+02   -9.24942e-04    2.52628e+02    3.55534e-03    4.74003e-01\n",
      "             16    2.52347e+02   -9.28105e-04    2.52348e+02    3.54217e-03    4.83661e-01\n",
      "             17    2.52099e+02   -1.00415e-03    2.52100e+02    3.36755e-03    4.80189e-01\n",
      "             18    2.51857e+02   -1.01294e-03    2.51858e+02    3.60960e-03    4.81543e-01\n",
      "             19    2.51662e+02   -1.03922e-03    2.51663e+02    3.72318e-03    4.79708e-01\n",
      "             20    2.51476e+02   -1.07865e-03    2.51477e+02    4.14771e-03    4.78318e-01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             21    2.51314e+02   -1.07743e-03    2.51315e+02    3.95868e-03    4.85748e-01\n",
      "             22    2.51201e+02   -1.12121e-03    2.51202e+02    3.82630e-03    4.83681e-01\n",
      "             23    2.51052e+02   -1.06844e-03    2.51053e+02    3.65530e-03    4.78874e-01\n",
      "             24    2.50914e+02   -1.16282e-03    2.50915e+02    3.91769e-03    4.79653e-01\n",
      "             25    2.50836e+02   -1.17618e-03    2.50837e+02    3.93158e-03    4.86394e-01\n",
      "             26    2.50719e+02   -1.18245e-03    2.50720e+02    3.84927e-03    4.78231e-01\n",
      "             27    2.50635e+02   -1.16203e-03    2.50636e+02    3.51938e-03    4.84351e-01\n",
      "             28    2.50557e+02   -1.25538e-03    2.50558e+02    4.03430e-03    4.83055e-01\n",
      "             29    2.50457e+02   -1.28193e-03    2.50458e+02    4.00776e-03    4.81409e-01\n",
      "kl div: 0.00400776\n",
      "kl coeff: 1.3732910156250002e-05\n",
      "rollouts time: 9.794663190841675\n",
      "shuffle time: 0.005086660385131836\n",
      "load time: 0.0016257762908935547\n",
      "sgd time: 19.054980754852295\n",
      "sgd examples/s: 2123.0144769208705\n",
      "total time so far: 671.330456495285\n",
      "TrainingResult(experiment_id='aaf6071946ae492eb28236dfaaae1b3c', training_iteration=20, episode_reward_mean=199.30392156862746, episode_len_mean=198.30392156862746, info={'kl_divergence': 0.0040077572, 'kl_coefficient': 1.3732910156250002e-05, 'rollouts_time': 9.794663190841675, 'shuffle_time': 0.005086660385131836, 'load_time': 0.0016257762908935547, 'sgd_time': 19.054980754852295, 'sample_throughput': 2123.0144769208705}, timesteps_this_iter=40454, timesteps_total=810985, time_this_iter_s=28.864397287368774, time_total_s=547.7045395374298)\n",
      "===> iteration 21\n",
      "total reward is  200.0\n",
      "trajectory length mean is  199.0\n",
      "timesteps: 40596\n",
      "Computing policy (iterations=30, stepsize=5e-05):\n",
      "           iter     total loss    policy loss        vf loss             kl        entropy\n",
      "              0    8.27205e+02    8.26013e-05    8.27204e+02    5.16334e-04    4.87961e-01\n",
      "              1    2.81787e+02   -1.47352e-04    2.81788e+02    1.11623e-03    4.98597e-01\n",
      "              2    2.63015e+02   -2.29589e-04    2.63015e+02    1.01475e-03    4.97187e-01\n",
      "              3    2.58857e+02   -3.08757e-04    2.58857e+02    1.23207e-03    4.98912e-01\n",
      "              4    2.56555e+02   -3.36844e-04    2.56555e+02    1.17283e-03    4.94770e-01\n",
      "              5    2.54804e+02   -4.92759e-04    2.54804e+02    1.69853e-03    5.02128e-01\n",
      "              6    2.53306e+02   -3.57730e-04    2.53307e+02    1.25787e-03    4.85006e-01\n",
      "              7    2.52006e+02   -4.66992e-04    2.52007e+02    1.68601e-03    4.95531e-01\n",
      "              8    2.50850e+02   -5.12633e-04    2.50850e+02    1.59559e-03    4.91628e-01\n",
      "              9    2.49836e+02   -5.37177e-04    2.49836e+02    1.91392e-03    4.94188e-01\n",
      "             10    2.48966e+02   -5.21985e-04    2.48967e+02    1.94109e-03    4.97495e-01\n",
      "             11    2.48219e+02   -5.84255e-04    2.48220e+02    1.90758e-03    4.91662e-01\n",
      "             12    2.47643e+02   -6.71740e-04    2.47643e+02    2.05657e-03    4.93479e-01\n",
      "             13    2.47148e+02   -6.93748e-04    2.47149e+02    1.83907e-03    4.89210e-01\n",
      "             14    2.46746e+02   -6.50801e-04    2.46747e+02    2.27846e-03    4.95273e-01\n",
      "             15    2.46376e+02   -7.75406e-04    2.46377e+02    2.53567e-03    4.95262e-01\n",
      "             16    2.46114e+02   -7.38903e-04    2.46114e+02    2.27341e-03    4.85487e-01\n",
      "             17    2.45847e+02   -7.42507e-04    2.45848e+02    1.96048e-03    4.94395e-01\n",
      "             18    2.45600e+02   -8.00025e-04    2.45601e+02    2.21562e-03    4.96620e-01\n",
      "             19    2.45411e+02   -8.08935e-04    2.45411e+02    2.10441e-03    4.90398e-01\n",
      "             20    2.45190e+02   -8.25463e-04    2.45191e+02    2.07917e-03    4.87060e-01\n",
      "             21    2.45063e+02   -8.63131e-04    2.45064e+02    2.25481e-03    4.91457e-01\n",
      "             22    2.44893e+02   -7.99548e-04    2.44894e+02    2.17676e-03    4.86731e-01\n",
      "             23    2.44731e+02   -8.69752e-04    2.44732e+02    2.22858e-03    4.89015e-01\n",
      "             24    2.44584e+02   -8.61967e-04    2.44585e+02    2.25595e-03    4.87009e-01\n",
      "             25    2.44457e+02   -9.25168e-04    2.44458e+02    2.18508e-03    4.91252e-01\n",
      "             26    2.44316e+02   -8.89087e-04    2.44317e+02    2.15947e-03    4.88849e-01\n",
      "             27    2.44217e+02   -9.66265e-04    2.44218e+02    2.30902e-03    4.89905e-01\n",
      "             28    2.44059e+02   -9.29609e-04    2.44060e+02    2.36331e-03    4.82927e-01\n",
      "             29    2.43983e+02   -9.84788e-04    2.43984e+02    2.45772e-03    4.87809e-01\n",
      "kl div: 0.00245772\n",
      "kl coeff: 6.866455078125001e-06\n",
      "rollouts time: 9.934332132339478\n",
      "shuffle time: 0.004296541213989258\n",
      "load time: 0.0014519691467285156\n",
      "sgd time: 16.5924870967865\n",
      "sgd examples/s: 2446.649484383948\n",
      "total time so far: 697.8690340518951\n",
      "TrainingResult(experiment_id='aaf6071946ae492eb28236dfaaae1b3c', training_iteration=21, episode_reward_mean=200.0, episode_len_mean=199.0, info={'kl_divergence': 0.0024577249, 'kl_coefficient': 6.866455078125001e-06, 'rollouts_time': 9.934332132339478, 'shuffle_time': 0.004296541213989258, 'load_time': 0.0014519691467285156, 'sgd_time': 16.5924870967865, 'sample_throughput': 2446.649484383948}, timesteps_this_iter=40596, timesteps_total=851581, time_this_iter_s=26.538410186767578, time_total_s=574.2429497241974)\n",
      "===> iteration 22\n",
      "total reward is  199.759803922\n",
      "trajectory length mean is  198.759803922\n",
      "timesteps: 40547\n",
      "Computing policy (iterations=30, stepsize=5e-05):\n",
      "           iter     total loss    policy loss        vf loss             kl        entropy\n",
      "              0    5.30684e+02   -3.01867e-05    5.30684e+02    4.48472e-04    4.92028e-01\n",
      "              1    2.62292e+02   -3.43317e-04    2.62292e+02    1.12340e-03    4.95303e-01\n",
      "              2    2.48776e+02   -5.53535e-04    2.48777e+02    2.21130e-03    4.99674e-01\n",
      "              3    2.46415e+02   -8.08936e-04    2.46416e+02    2.60442e-03    4.99112e-01\n",
      "              4    2.45333e+02   -9.34630e-04    2.45334e+02    2.05423e-03    4.79206e-01\n",
      "              5    2.44546e+02   -9.88060e-04    2.44547e+02    2.34423e-03    4.83360e-01\n",
      "              6    2.43927e+02   -1.13054e-03    2.43928e+02    2.92374e-03    4.89444e-01\n",
      "              7    2.43414e+02   -1.18433e-03    2.43415e+02    2.62677e-03    4.87366e-01\n",
      "              8    2.42961e+02   -1.25270e-03    2.42962e+02    2.82123e-03    4.83281e-01\n",
      "              9    2.42613e+02   -1.30888e-03    2.42614e+02    2.85868e-03    4.76667e-01\n",
      "             10    2.42291e+02   -1.39289e-03    2.42293e+02    3.22163e-03    4.87683e-01\n",
      "             11    2.42057e+02   -1.40450e-03    2.42059e+02    3.01192e-03    4.80046e-01\n",
      "             12    2.41822e+02   -1.50649e-03    2.41823e+02    2.99668e-03    4.80330e-01\n",
      "             13    2.41577e+02   -1.59781e-03    2.41578e+02    3.59451e-03    4.80738e-01\n",
      "             14    2.41406e+02   -1.61179e-03    2.41408e+02    3.35935e-03    4.83713e-01\n",
      "             15    2.41201e+02   -1.68359e-03    2.41203e+02    3.58726e-03    4.83795e-01\n",
      "             16    2.41047e+02   -1.66241e-03    2.41049e+02    3.67011e-03    4.74906e-01\n",
      "             17    2.40929e+02   -1.71039e-03    2.40931e+02    3.75424e-03    4.80165e-01\n",
      "             18    2.40745e+02   -1.76059e-03    2.40747e+02    3.75853e-03    4.78547e-01\n",
      "             19    2.40635e+02   -1.78043e-03    2.40636e+02    3.71534e-03    4.79394e-01\n",
      "             20    2.40515e+02   -1.83552e-03    2.40517e+02    3.82752e-03    4.82302e-01\n",
      "             21    2.40418e+02   -1.88933e-03    2.40420e+02    4.06433e-03    4.77120e-01\n",
      "             22    2.40290e+02   -1.84468e-03    2.40292e+02    4.09223e-03    4.77104e-01\n",
      "             23    2.40200e+02   -1.93214e-03    2.40202e+02    4.09052e-03    4.79027e-01\n",
      "             24    2.40110e+02   -1.93036e-03    2.40112e+02    4.34245e-03    4.77966e-01\n",
      "             25    2.40012e+02   -1.98897e-03    2.40014e+02    4.33362e-03    4.77274e-01\n",
      "             26    2.39921e+02   -2.03341e-03    2.39923e+02    4.38566e-03    4.75468e-01\n",
      "             27    2.39828e+02   -2.00031e-03    2.39830e+02    4.32910e-03    4.79061e-01\n",
      "             28    2.39744e+02   -2.05120e-03    2.39746e+02    4.38896e-03    4.76850e-01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             29    2.39670e+02   -2.04095e-03    2.39672e+02    4.44236e-03    4.77602e-01\n",
      "kl div: 0.00444236\n",
      "kl coeff: 3.4332275390625005e-06\n",
      "rollouts time: 8.55243468284607\n",
      "shuffle time: 0.004193782806396484\n",
      "load time: 0.0015778541564941406\n",
      "sgd time: 17.775023221969604\n",
      "sgd examples/s: 2281.122195659618\n",
      "total time so far: 724.2080056667328\n",
      "TrainingResult(experiment_id='aaf6071946ae492eb28236dfaaae1b3c', training_iteration=22, episode_reward_mean=199.75980392156862, episode_len_mean=198.75980392156862, info={'kl_divergence': 0.0044423635, 'kl_coefficient': 3.4332275390625005e-06, 'rollouts_time': 8.55243468284607, 'shuffle_time': 0.004193782806396484, 'load_time': 0.0015778541564941406, 'sgd_time': 17.775023221969604, 'sample_throughput': 2281.122195659618}, timesteps_this_iter=40547, timesteps_total=892128, time_this_iter_s=26.33870029449463, time_total_s=600.581650018692)\n",
      "===> iteration 23\n",
      "total reward is  199.549019608\n",
      "trajectory length mean is  198.549019608\n",
      "timesteps: 40504\n",
      "Computing policy (iterations=30, stepsize=5e-05):\n",
      "           iter     total loss    policy loss        vf loss             kl        entropy\n",
      "              0    7.59952e+02    1.11010e-04    7.59951e+02    5.01865e-04    4.81247e-01\n",
      "              1    2.75268e+02   -1.14229e-04    2.75268e+02    1.23619e-03    4.91119e-01\n",
      "              2    2.64508e+02   -2.70861e-04    2.64509e+02    2.57319e-03    4.98660e-01\n",
      "              3    2.62072e+02   -3.80340e-04    2.62072e+02    2.56621e-03    4.90998e-01\n",
      "              4    2.60528e+02   -4.83484e-04    2.60528e+02    2.82671e-03    4.94953e-01\n",
      "              5    2.59305e+02   -5.47046e-04    2.59306e+02    2.89546e-03    4.90075e-01\n",
      "              6    2.58349e+02   -4.51202e-04    2.58350e+02    2.22191e-03    4.86083e-01\n",
      "              7    2.57572e+02   -5.85601e-04    2.57573e+02    2.79538e-03    4.91006e-01\n",
      "              8    2.56961e+02   -7.01992e-04    2.56962e+02    3.37613e-03    4.92708e-01\n",
      "              9    2.56447e+02   -7.26138e-04    2.56448e+02    3.38071e-03    4.89963e-01\n",
      "             10    2.55991e+02   -7.58374e-04    2.55992e+02    3.31270e-03    4.86621e-01\n",
      "             11    2.55689e+02   -8.19435e-04    2.55689e+02    3.44037e-03    4.87231e-01\n",
      "             12    2.55396e+02   -8.70394e-04    2.55397e+02    3.31631e-03    4.82029e-01\n",
      "             13    2.55096e+02   -9.19084e-04    2.55097e+02    3.47631e-03    4.86239e-01\n",
      "             14    2.54870e+02   -1.02321e-03    2.54871e+02    3.90243e-03    4.87676e-01\n",
      "             15    2.54706e+02   -9.75402e-04    2.54707e+02    3.03047e-03    4.85974e-01\n",
      "             16    2.54517e+02   -1.03561e-03    2.54518e+02    3.59429e-03    4.83369e-01\n",
      "             17    2.54333e+02   -1.07247e-03    2.54334e+02    3.23751e-03    4.84620e-01\n",
      "             18    2.54184e+02   -1.11591e-03    2.54186e+02    3.53383e-03    4.85788e-01\n",
      "             19    2.54053e+02   -1.19237e-03    2.54054e+02    4.20804e-03    4.85323e-01\n",
      "             20    2.53880e+02   -1.19596e-03    2.53881e+02    3.83075e-03    4.80408e-01\n",
      "             21    2.53772e+02   -1.22031e-03    2.53773e+02    3.64080e-03    4.79322e-01\n",
      "             22    2.53648e+02   -1.27720e-03    2.53649e+02    4.01382e-03    4.86640e-01\n",
      "             23    2.53504e+02   -1.26841e-03    2.53505e+02    4.00439e-03    4.78341e-01\n",
      "             24    2.53413e+02   -1.38825e-03    2.53415e+02    4.04271e-03    4.89660e-01\n",
      "             25    2.53328e+02   -1.22511e-03    2.53329e+02    3.90396e-03    4.73868e-01\n",
      "             26    2.53208e+02   -1.39661e-03    2.53210e+02    3.70484e-03    4.81400e-01\n",
      "             27    2.53113e+02   -1.39056e-03    2.53114e+02    3.73192e-03    4.82059e-01\n",
      "             28    2.52986e+02   -1.48670e-03    2.52988e+02    4.50140e-03    4.84882e-01\n",
      "             29    2.52894e+02   -1.41403e-03    2.52895e+02    3.48171e-03    4.74071e-01\n",
      "kl div: 0.00348171\n",
      "kl coeff: 1.7166137695312503e-06\n",
      "rollouts time: 8.507878541946411\n",
      "shuffle time: 0.004240751266479492\n",
      "load time: 0.0014717578887939453\n",
      "sgd time: 17.86099147796631\n",
      "sgd examples/s: 2267.7352514258\n",
      "total time so far: 750.5881617069244\n",
      "TrainingResult(experiment_id='aaf6071946ae492eb28236dfaaae1b3c', training_iteration=23, episode_reward_mean=199.54901960784315, episode_len_mean=198.54901960784315, info={'kl_divergence': 0.003481708, 'kl_coefficient': 1.7166137695312503e-06, 'rollouts_time': 8.507878541946411, 'shuffle_time': 0.004240751266479492, 'load_time': 0.0014717578887939453, 'sgd_time': 17.86099147796631, 'sample_throughput': 2267.7352514258}, timesteps_this_iter=40504, timesteps_total=932632, time_this_iter_s=26.38001036643982, time_total_s=626.9616603851318)\n",
      "===> iteration 24\n",
      "total reward is  198.921568627\n",
      "trajectory length mean is  197.921568627\n",
      "timesteps: 40376\n",
      "Computing policy (iterations=30, stepsize=5e-05):\n",
      "           iter     total loss    policy loss        vf loss             kl        entropy\n",
      "              0    5.12252e+02    3.09174e-04    5.12252e+02    4.08408e-04    4.71298e-01\n",
      "              1    2.65323e+02    9.71167e-05    2.65323e+02    3.37039e-04    4.75831e-01\n",
      "              2    2.56927e+02    7.49543e-06    2.56927e+02    1.03849e-03    4.71456e-01\n",
      "              3    2.55718e+02   -1.11471e-04    2.55719e+02    1.66545e-03    4.65473e-01\n",
      "              4    2.55037e+02   -2.39286e-04    2.55037e+02    1.78021e-03    4.73305e-01\n",
      "              5    2.54479e+02   -3.75728e-04    2.54479e+02    2.23561e-03    4.71596e-01\n",
      "              6    2.53969e+02   -4.29851e-04    2.53969e+02    2.95583e-03    4.68759e-01\n",
      "              7    2.53528e+02   -5.65380e-04    2.53528e+02    2.36111e-03    4.75324e-01\n",
      "              8    2.53104e+02   -5.68669e-04    2.53104e+02    2.82643e-03    4.74107e-01\n",
      "              9    2.52747e+02   -6.72893e-04    2.52748e+02    2.89821e-03    4.70298e-01\n",
      "             10    2.52371e+02   -7.07618e-04    2.52372e+02    2.89226e-03    4.72854e-01\n",
      "             11    2.52069e+02   -7.56652e-04    2.52070e+02    3.25358e-03    4.72118e-01\n",
      "             12    2.51738e+02   -7.97878e-04    2.51739e+02    3.68558e-03    4.67877e-01\n",
      "             13    2.51483e+02   -8.04060e-04    2.51484e+02    3.33962e-03    4.73041e-01\n",
      "             14    2.51260e+02   -8.18342e-04    2.51261e+02    3.90610e-03    4.70320e-01\n",
      "             15    2.51050e+02   -8.83888e-04    2.51051e+02    3.36798e-03    4.69437e-01\n",
      "             16    2.50866e+02   -9.14608e-04    2.50867e+02    3.56153e-03    4.69699e-01\n",
      "             17    2.50705e+02   -9.01623e-04    2.50706e+02    3.54951e-03    4.71368e-01\n",
      "             18    2.50555e+02   -9.36403e-04    2.50556e+02    3.62495e-03    4.70820e-01\n",
      "             19    2.50416e+02   -1.03333e-03    2.50418e+02    3.87528e-03    4.67075e-01\n",
      "             20    2.50309e+02   -9.74398e-04    2.50310e+02    3.11418e-03    4.74491e-01\n",
      "             21    2.50184e+02   -1.02069e-03    2.50185e+02    4.00402e-03    4.67343e-01\n",
      "             22    2.50043e+02   -9.85444e-04    2.50044e+02    3.46508e-03    4.72787e-01\n",
      "             23    2.49979e+02   -1.12722e-03    2.49980e+02    4.02899e-03    4.66731e-01\n",
      "             24    2.49877e+02   -1.09522e-03    2.49878e+02    3.50307e-03    4.66683e-01\n",
      "             25    2.49782e+02   -1.13810e-03    2.49783e+02    4.04308e-03    4.67997e-01\n",
      "             26    2.49726e+02   -1.09004e-03    2.49727e+02    3.59697e-03    4.70993e-01\n",
      "             27    2.49655e+02   -1.14084e-03    2.49656e+02    3.97779e-03    4.69438e-01\n",
      "             28    2.49557e+02   -1.19046e-03    2.49558e+02    3.53195e-03    4.73686e-01\n",
      "             29    2.49508e+02   -1.15383e-03    2.49509e+02    3.86771e-03    4.68264e-01\n",
      "kl div: 0.00386771\n",
      "kl coeff: 8.583068847656251e-07\n",
      "rollouts time: 8.670821905136108\n",
      "shuffle time: 0.007152557373046875\n",
      "load time: 0.0016257762908935547\n",
      "sgd time: 19.440178394317627\n",
      "sgd examples/s: 2076.935673172728\n",
      "total time so far: 778.7170243263245\n",
      "TrainingResult(experiment_id='aaf6071946ae492eb28236dfaaae1b3c', training_iteration=24, episode_reward_mean=198.92156862745097, episode_len_mean=197.92156862745097, info={'kl_divergence': 0.0038677074, 'kl_coefficient': 8.583068847656251e-07, 'rollouts_time': 8.670821905136108, 'shuffle_time': 0.007152557373046875, 'load_time': 0.0016257762908935547, 'sgd_time': 19.440178394317627, 'sample_throughput': 2076.935673172728}, timesteps_this_iter=40376, timesteps_total=973008, time_this_iter_s=28.129066228866577, time_total_s=655.0907266139984)\n",
      "===> iteration 25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total reward is  200.0\n",
      "trajectory length mean is  199.0\n",
      "timesteps: 40596\n",
      "Computing policy (iterations=30, stepsize=5e-05):\n",
      "           iter     total loss    policy loss        vf loss             kl        entropy\n",
      "              0    6.45931e+02   -2.44956e-04    6.45931e+02    9.26459e-04    4.76205e-01\n",
      "              1    2.71145e+02   -4.88182e-04    2.71145e+02    1.22332e-03    4.80724e-01\n",
      "              2    2.64441e+02   -8.39268e-04    2.64442e+02    3.69750e-03    4.82266e-01\n",
      "              3    2.61715e+02   -8.80819e-04    2.61716e+02    3.11283e-03    4.85109e-01\n",
      "              4    2.59886e+02   -9.13358e-04    2.59887e+02    2.61473e-03    4.81559e-01\n",
      "              5    2.58669e+02   -1.05123e-03    2.58670e+02    3.17944e-03    4.81710e-01\n",
      "              6    2.57752e+02   -1.07925e-03    2.57753e+02    3.56603e-03    4.78330e-01\n",
      "              7    2.56974e+02   -1.23097e-03    2.56976e+02    3.67543e-03    4.81806e-01\n",
      "              8    2.56326e+02   -1.24567e-03    2.56327e+02    2.64050e-03    4.75221e-01\n",
      "              9    2.55745e+02   -1.31079e-03    2.55747e+02    3.62618e-03    4.77577e-01\n",
      "             10    2.55268e+02   -1.27145e-03    2.55269e+02    3.46811e-03    4.74367e-01\n",
      "             11    2.54834e+02   -1.37937e-03    2.54835e+02    3.30387e-03    4.78915e-01\n",
      "             12    2.54441e+02   -1.50862e-03    2.54443e+02    3.32854e-03    4.78687e-01\n",
      "             13    2.54060e+02   -1.32811e-03    2.54062e+02    3.20297e-03    4.74448e-01\n",
      "             14    2.53737e+02   -1.52340e-03    2.53738e+02    3.54336e-03    4.77639e-01\n",
      "             15    2.53397e+02   -1.53386e-03    2.53399e+02    3.46540e-03    4.74800e-01\n",
      "             16    2.53147e+02   -1.59390e-03    2.53148e+02    3.54771e-03    4.74636e-01\n",
      "             17    2.52884e+02   -1.57632e-03    2.52886e+02    3.64513e-03    4.76672e-01\n",
      "             18    2.52693e+02   -1.64406e-03    2.52695e+02    3.18075e-03    4.76115e-01\n",
      "             19    2.52500e+02   -1.71534e-03    2.52502e+02    3.61214e-03    4.75125e-01\n",
      "             20    2.52346e+02   -1.74923e-03    2.52348e+02    3.41549e-03    4.75133e-01\n",
      "             21    2.52179e+02   -1.65311e-03    2.52180e+02    3.46924e-03    4.71782e-01\n",
      "             22    2.52026e+02   -1.75901e-03    2.52027e+02    3.83066e-03    4.73237e-01\n",
      "             23    2.51898e+02   -1.78719e-03    2.51900e+02    3.80750e-03    4.73795e-01\n",
      "             24    2.51757e+02   -1.82497e-03    2.51759e+02    3.71840e-03    4.72572e-01\n",
      "             25    2.51644e+02   -1.90379e-03    2.51646e+02    3.61599e-03    4.74439e-01\n",
      "             26    2.51527e+02   -1.79238e-03    2.51528e+02    3.41498e-03    4.66786e-01\n",
      "             27    2.51431e+02   -1.85187e-03    2.51433e+02    4.01144e-03    4.75993e-01\n",
      "             28    2.51299e+02   -1.88761e-03    2.51301e+02    3.97053e-03    4.71012e-01\n",
      "             29    2.51170e+02   -1.96396e-03    2.51172e+02    4.25694e-03    4.73935e-01\n",
      "kl div: 0.00425694\n",
      "kl coeff: 4.2915344238281256e-07\n",
      "rollouts time: 8.541119575500488\n",
      "shuffle time: 0.004178047180175781\n",
      "load time: 0.001344919204711914\n",
      "sgd time: 18.087913990020752\n",
      "sgd examples/s: 2244.3715744334663\n",
      "total time so far: 805.3583817481995\n",
      "TrainingResult(experiment_id='aaf6071946ae492eb28236dfaaae1b3c', training_iteration=25, episode_reward_mean=200.0, episode_len_mean=199.0, info={'kl_divergence': 0.0042569358, 'kl_coefficient': 4.2915344238281256e-07, 'rollouts_time': 8.541119575500488, 'shuffle_time': 0.004178047180175781, 'load_time': 0.001344919204711914, 'sgd_time': 18.087913990020752, 'sample_throughput': 2244.3715744334663}, timesteps_this_iter=40596, timesteps_total=1013604, time_this_iter_s=26.640682697296143, time_total_s=681.7314093112946)\n",
      "===> iteration 26\n",
      "total reward is  199.073529412\n",
      "trajectory length mean is  198.073529412\n",
      "timesteps: 40407\n",
      "Computing policy (iterations=30, stepsize=5e-05):\n",
      "           iter     total loss    policy loss        vf loss             kl        entropy\n",
      "              0    4.75806e+02    5.04160e-04    4.75805e+02    2.60170e-04    4.64981e-01\n",
      "              1    2.67550e+02    3.21185e-04    2.67550e+02    1.67176e-03    4.56797e-01\n",
      "              2    2.61876e+02    1.27817e-04    2.61876e+02    2.82053e-03    4.45376e-01\n",
      "              3    2.61234e+02   -1.60548e-05    2.61234e+02    3.09561e-03    4.44756e-01\n",
      "              4    2.60793e+02   -8.73834e-05    2.60793e+02    4.05888e-03    4.42046e-01\n",
      "              5    2.60401e+02   -1.09628e-04    2.60401e+02    3.58416e-03    4.43574e-01\n",
      "              6    2.60085e+02   -2.03056e-04    2.60086e+02    4.27008e-03    4.45454e-01\n",
      "              7    2.59792e+02   -2.28416e-04    2.59792e+02    3.66765e-03    4.44205e-01\n",
      "              8    2.59541e+02   -3.42115e-04    2.59541e+02    3.89753e-03    4.44797e-01\n",
      "              9    2.59288e+02   -3.70338e-04    2.59288e+02    4.28248e-03    4.45284e-01\n",
      "             10    2.59089e+02   -4.45429e-04    2.59090e+02    4.53141e-03    4.43388e-01\n",
      "             11    2.58907e+02   -4.51125e-04    2.58908e+02    3.16696e-03    4.42537e-01\n",
      "             12    2.58726e+02   -5.19623e-04    2.58727e+02    3.42387e-03    4.41994e-01\n",
      "             13    2.58590e+02   -6.16704e-04    2.58590e+02    4.53311e-03    4.45027e-01\n",
      "             14    2.58430e+02   -6.89515e-04    2.58431e+02    3.58340e-03    4.41239e-01\n",
      "             15    2.58285e+02   -6.15616e-04    2.58286e+02    3.94605e-03    4.51070e-01\n",
      "             16    2.58196e+02   -7.77478e-04    2.58197e+02    3.87633e-03    4.43727e-01\n",
      "             17    2.58031e+02   -9.24899e-04    2.58031e+02    4.33692e-03    4.48304e-01\n",
      "             18    2.58000e+02   -8.17589e-04    2.58001e+02    3.65641e-03    4.45432e-01\n",
      "             19    2.57795e+02   -9.67284e-04    2.57796e+02    3.41089e-03    4.43665e-01\n",
      "             20    2.57744e+02   -8.87578e-04    2.57745e+02    3.56072e-03    4.49199e-01\n",
      "             21    2.57640e+02   -1.04103e-03    2.57641e+02    3.43664e-03    4.49621e-01\n",
      "             22    2.57522e+02   -1.12455e-03    2.57523e+02    4.19344e-03    4.47324e-01\n",
      "             23    2.57437e+02   -1.16023e-03    2.57438e+02    3.59885e-03    4.49921e-01\n",
      "             24    2.57345e+02   -1.16366e-03    2.57346e+02    4.02851e-03    4.47055e-01\n",
      "             25    2.57259e+02   -1.31224e-03    2.57261e+02    4.17047e-03    4.47288e-01\n",
      "             26    2.57167e+02   -1.17727e-03    2.57168e+02    3.68332e-03    4.55413e-01\n",
      "             27    2.57092e+02   -1.33048e-03    2.57094e+02    3.61173e-03    4.48917e-01\n",
      "             28    2.57002e+02   -1.32432e-03    2.57004e+02    4.35521e-03    4.49943e-01\n",
      "             29    2.56916e+02   -1.38900e-03    2.56917e+02    4.31625e-03    4.50476e-01\n",
      "kl div: 0.00431625\n",
      "kl coeff: 2.1457672119140628e-07\n",
      "rollouts time: 9.739691257476807\n",
      "shuffle time: 0.004419088363647461\n",
      "load time: 0.0014123916625976562\n",
      "sgd time: 20.5220844745636\n",
      "sgd examples/s: 1968.952035553847\n",
      "total time so far: 835.6329078674316\n",
      "TrainingResult(experiment_id='aaf6071946ae492eb28236dfaaae1b3c', training_iteration=26, episode_reward_mean=199.0735294117647, episode_len_mean=198.0735294117647, info={'kl_divergence': 0.0043162536, 'kl_coefficient': 2.1457672119140628e-07, 'rollouts_time': 9.739691257476807, 'shuffle_time': 0.004419088363647461, 'load_time': 0.0014123916625976562, 'sgd_time': 20.5220844745636, 'sample_throughput': 1968.952035553847}, timesteps_this_iter=40407, timesteps_total=1054011, time_this_iter_s=30.274526834487915, time_total_s=712.0059361457825)\n",
      "===> iteration 27\n",
      "total reward is  200.0\n",
      "trajectory length mean is  199.0\n",
      "timesteps: 40596\n",
      "Computing policy (iterations=30, stepsize=5e-05):\n",
      "           iter     total loss    policy loss        vf loss             kl        entropy\n",
      "              0    6.30627e+02   -1.60226e-04    6.30627e+02    1.09002e-03    4.69150e-01\n",
      "              1    2.63471e+02   -6.27023e-04    2.63472e+02    1.66553e-03    4.74678e-01\n",
      "              2    2.58929e+02   -8.33774e-04    2.58930e+02    2.64983e-03    4.81054e-01\n",
      "              3    2.57740e+02   -8.69924e-04    2.57741e+02    2.77158e-03    4.76029e-01\n",
      "              4    2.56746e+02   -9.96920e-04    2.56747e+02    2.64328e-03    4.73153e-01\n",
      "              5    2.55880e+02   -1.01389e-03    2.55881e+02    3.23887e-03    4.77764e-01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              6    2.55119e+02   -1.12380e-03    2.55120e+02    3.19432e-03    4.79038e-01\n",
      "              7    2.54458e+02   -1.12832e-03    2.54459e+02    3.22281e-03    4.78515e-01\n",
      "              8    2.53846e+02   -1.21437e-03    2.53847e+02    3.15948e-03    4.78209e-01\n",
      "              9    2.53410e+02   -1.23193e-03    2.53411e+02    3.35429e-03    4.79563e-01\n",
      "             10    2.52990e+02   -1.36831e-03    2.52991e+02    3.72556e-03    4.80335e-01\n",
      "             11    2.52624e+02   -1.22047e-03    2.52625e+02    3.07186e-03    4.74750e-01\n",
      "             12    2.52315e+02   -1.34016e-03    2.52316e+02    3.44804e-03    4.76037e-01\n",
      "             13    2.52044e+02   -1.39446e-03    2.52046e+02    3.85545e-03    4.78537e-01\n",
      "             14    2.51792e+02   -1.54057e-03    2.51794e+02    3.77408e-03    4.80040e-01\n",
      "             15    2.51565e+02   -1.39639e-03    2.51567e+02    3.44713e-03    4.76223e-01\n",
      "             16    2.51306e+02   -1.57637e-03    2.51308e+02    3.52589e-03    4.78989e-01\n",
      "             17    2.51195e+02   -1.50732e-03    2.51197e+02    3.90673e-03    4.78621e-01\n",
      "             18    2.51024e+02   -1.66388e-03    2.51026e+02    3.86371e-03    4.80030e-01\n",
      "             19    2.50898e+02   -1.60928e-03    2.50899e+02    3.69747e-03    4.74680e-01\n",
      "             20    2.50729e+02   -1.66311e-03    2.50730e+02    3.80261e-03    4.77610e-01\n",
      "             21    2.50649e+02   -1.78063e-03    2.50650e+02    3.89324e-03    4.77686e-01\n",
      "             22    2.50517e+02   -1.61216e-03    2.50519e+02    3.66271e-03    4.74698e-01\n",
      "             23    2.50395e+02   -1.69390e-03    2.50397e+02    3.63965e-03    4.74539e-01\n",
      "             24    2.50294e+02   -1.77383e-03    2.50295e+02    3.69769e-03    4.74245e-01\n",
      "             25    2.50238e+02   -1.71819e-03    2.50240e+02    3.88622e-03    4.74966e-01\n",
      "             26    2.50167e+02   -1.73057e-03    2.50168e+02    3.58871e-03    4.75849e-01\n",
      "             27    2.50030e+02   -1.74806e-03    2.50031e+02    3.99555e-03    4.76223e-01\n",
      "             28    2.49945e+02   -1.81998e-03    2.49947e+02    3.87746e-03    4.76319e-01\n",
      "             29    2.49915e+02   -1.85406e-03    2.49916e+02    4.35261e-03    4.79397e-01\n",
      "kl div: 0.00435261\n",
      "kl coeff: 1.0728836059570314e-07\n",
      "rollouts time: 8.526942729949951\n",
      "shuffle time: 0.004346609115600586\n",
      "load time: 0.001468658447265625\n",
      "sgd time: 17.976526737213135\n",
      "sgd examples/s: 2258.2782866482426\n",
      "total time so far: 862.1484870910645\n",
      "TrainingResult(experiment_id='aaf6071946ae492eb28236dfaaae1b3c', training_iteration=27, episode_reward_mean=200.0, episode_len_mean=199.0, info={'kl_divergence': 0.0043526073, 'kl_coefficient': 1.0728836059570314e-07, 'rollouts_time': 8.526942729949951, 'shuffle_time': 0.004346609115600586, 'load_time': 0.001468658447265625, 'sgd_time': 17.976526737213135, 'sample_throughput': 2258.2782866482426}, timesteps_this_iter=40596, timesteps_total=1094607, time_this_iter_s=26.51521062850952, time_total_s=738.521146774292)\n",
      "===> iteration 28\n",
      "total reward is  200.0\n",
      "trajectory length mean is  199.0\n",
      "timesteps: 40596\n",
      "Computing policy (iterations=30, stepsize=5e-05):\n",
      "           iter     total loss    policy loss        vf loss             kl        entropy\n",
      "              0    4.64262e+02   -4.62377e-04    4.64262e+02    1.29508e-03    4.60402e-01\n",
      "              1    2.65162e+02   -1.19413e-03    2.65163e+02    4.30023e-03    4.46835e-01\n",
      "              2    2.61158e+02   -1.43441e-03    2.61160e+02    5.07847e-03    4.54042e-01\n",
      "              3    2.60352e+02   -1.43489e-03    2.60354e+02    4.57623e-03    4.46279e-01\n",
      "              4    2.59733e+02   -1.69874e-03    2.59734e+02    5.25412e-03    4.56452e-01\n",
      "              5    2.59163e+02   -1.71615e-03    2.59165e+02    4.96792e-03    4.47207e-01\n",
      "              6    2.58663e+02   -1.77656e-03    2.58665e+02    5.07469e-03    4.49529e-01\n",
      "              7    2.58220e+02   -1.80958e-03    2.58222e+02    5.49765e-03    4.54932e-01\n",
      "              8    2.57812e+02   -1.87377e-03    2.57814e+02    5.54138e-03    4.53920e-01\n",
      "              9    2.57480e+02   -1.96223e-03    2.57482e+02    5.57986e-03    4.49272e-01\n",
      "             10    2.57124e+02   -1.91713e-03    2.57126e+02    5.58811e-03    4.54460e-01\n",
      "             11    2.56828e+02   -2.00839e-03    2.56830e+02    5.92031e-03    4.51818e-01\n",
      "             12    2.56534e+02   -2.04698e-03    2.56536e+02    5.90108e-03    4.53199e-01\n",
      "             13    2.56236e+02   -2.05424e-03    2.56238e+02    5.98247e-03    4.51938e-01\n",
      "             14    2.56038e+02   -2.08027e-03    2.56040e+02    5.78307e-03    4.51000e-01\n",
      "             15    2.55772e+02   -2.13037e-03    2.55774e+02    5.55214e-03    4.50711e-01\n",
      "             16    2.55589e+02   -2.15101e-03    2.55592e+02    6.20148e-03    4.52952e-01\n",
      "             17    2.55379e+02   -2.16147e-03    2.55382e+02    5.82590e-03    4.51837e-01\n",
      "             18    2.55209e+02   -2.16036e-03    2.55211e+02    6.09400e-03    4.53147e-01\n",
      "             19    2.54985e+02   -2.25910e-03    2.54987e+02    5.99096e-03    4.50985e-01\n",
      "             20    2.54842e+02   -2.15721e-03    2.54844e+02    6.12917e-03    4.52272e-01\n",
      "             21    2.54669e+02   -2.19966e-03    2.54671e+02    6.22283e-03    4.53241e-01\n",
      "             22    2.54495e+02   -2.19380e-03    2.54497e+02    6.10329e-03    4.52257e-01\n",
      "             23    2.54294e+02   -2.29932e-03    2.54296e+02    6.24897e-03    4.53656e-01\n",
      "             24    2.54187e+02   -2.21952e-03    2.54189e+02    6.29270e-03    4.50910e-01\n",
      "             25    2.54025e+02   -2.31193e-03    2.54027e+02    6.29061e-03    4.50558e-01\n",
      "             26    2.53860e+02   -2.30994e-03    2.53862e+02    6.07433e-03    4.56420e-01\n",
      "             27    2.53733e+02   -2.28668e-03    2.53735e+02    6.21502e-03    4.52351e-01\n",
      "             28    2.53672e+02   -2.33548e-03    2.53674e+02    6.19178e-03    4.52265e-01\n",
      "             29    2.53571e+02   -2.35733e-03    2.53573e+02    6.32866e-03    4.51866e-01\n",
      "kl div: 0.00632866\n",
      "kl coeff: 1.0728836059570314e-07\n",
      "rollouts time: 8.50397801399231\n",
      "shuffle time: 0.007879495620727539\n",
      "load time: 0.002175569534301758\n",
      "sgd time: 17.9543879032135\n",
      "sgd examples/s: 2261.0628788260765\n",
      "total time so far: 888.6236643791199\n",
      "TrainingResult(experiment_id='aaf6071946ae492eb28236dfaaae1b3c', training_iteration=28, episode_reward_mean=200.0, episode_len_mean=199.0, info={'kl_divergence': 0.0063286647, 'kl_coefficient': 1.0728836059570314e-07, 'rollouts_time': 8.50397801399231, 'shuffle_time': 0.007879495620727539, 'load_time': 0.002175569534301758, 'sgd_time': 17.9543879032135, 'sample_throughput': 2261.0628788260765}, timesteps_this_iter=40596, timesteps_total=1135203, time_this_iter_s=26.47502851486206, time_total_s=764.996175289154)\n",
      "===> iteration 29\n",
      "total reward is  200.0\n",
      "trajectory length mean is  199.0\n",
      "timesteps: 40596\n",
      "Computing policy (iterations=30, stepsize=5e-05):\n",
      "           iter     total loss    policy loss        vf loss             kl        entropy\n",
      "              0    6.08682e+02    1.00942e-04    6.08682e+02    3.61792e-04    4.49903e-01\n",
      "              1    2.66633e+02   -2.52469e-04    2.66634e+02    9.74797e-04    4.41217e-01\n",
      "              2    2.61317e+02   -4.42379e-04    2.61318e+02    1.99509e-03    4.38725e-01\n",
      "              3    2.59319e+02   -6.62489e-04    2.59319e+02    2.62962e-03    4.38784e-01\n",
      "              4    2.57061e+02   -7.98488e-04    2.57062e+02    3.04851e-03    4.38638e-01\n",
      "              5    2.55277e+02   -7.61086e-04    2.55278e+02    2.87307e-03    4.46240e-01\n",
      "              6    2.54211e+02   -9.02474e-04    2.54212e+02    3.56130e-03    4.43200e-01\n",
      "              7    2.53358e+02   -1.07164e-03    2.53359e+02    3.50915e-03    4.42196e-01\n",
      "              8    2.52706e+02   -1.01987e-03    2.52707e+02    4.10924e-03    4.41246e-01\n",
      "              9    2.52181e+02   -1.07486e-03    2.52182e+02    3.54829e-03    4.46742e-01\n",
      "             10    2.51780e+02   -1.28878e-03    2.51781e+02    4.26435e-03    4.42177e-01\n",
      "             11    2.51465e+02   -1.09043e-03    2.51466e+02    3.54447e-03    4.48631e-01\n",
      "             12    2.51203e+02   -1.26330e-03    2.51204e+02    3.99227e-03    4.43863e-01\n",
      "             13    2.50934e+02   -1.37736e-03    2.50935e+02    4.54363e-03    4.41306e-01\n",
      "             14    2.50738e+02   -1.23562e-03    2.50739e+02    4.30501e-03    4.44502e-01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             15    2.50532e+02   -1.35098e-03    2.50533e+02    4.24358e-03    4.46597e-01\n",
      "             16    2.50350e+02   -1.45305e-03    2.50352e+02    4.20984e-03    4.43061e-01\n",
      "             17    2.50172e+02   -1.60370e-03    2.50174e+02    4.76084e-03    4.43436e-01\n",
      "             18    2.50044e+02   -1.39976e-03    2.50046e+02    4.03560e-03    4.46081e-01\n",
      "             19    2.49845e+02   -1.50178e-03    2.49846e+02    4.57734e-03    4.45918e-01\n",
      "             20    2.49733e+02   -1.57192e-03    2.49734e+02    4.58941e-03    4.45356e-01\n",
      "             21    2.49590e+02   -1.59434e-03    2.49592e+02    4.58839e-03    4.43902e-01\n",
      "             22    2.49484e+02   -1.56317e-03    2.49486e+02    4.68725e-03    4.44663e-01\n",
      "             23    2.49349e+02   -1.65161e-03    2.49350e+02    4.56106e-03    4.44231e-01\n",
      "             24    2.49261e+02   -1.63769e-03    2.49263e+02    4.68451e-03    4.46236e-01\n",
      "             25    2.49122e+02   -1.67790e-03    2.49123e+02    4.61360e-03    4.43296e-01\n",
      "             26    2.49038e+02   -1.70653e-03    2.49040e+02    4.67794e-03    4.46166e-01\n",
      "             27    2.48960e+02   -1.74425e-03    2.48962e+02    4.64567e-03    4.42798e-01\n",
      "             28    2.48873e+02   -1.83379e-03    2.48875e+02    4.99821e-03    4.44400e-01\n",
      "             29    2.48772e+02   -1.76956e-03    2.48773e+02    4.42623e-03    4.51879e-01\n",
      "kl div: 0.00442623\n",
      "kl coeff: 5.364418029785157e-08\n",
      "rollouts time: 8.653595447540283\n",
      "shuffle time: 0.004950523376464844\n",
      "load time: 0.001409769058227539\n",
      "sgd time: 17.928891897201538\n",
      "sgd examples/s: 2264.278251704808\n",
      "total time so far: 915.2180969715118\n",
      "TrainingResult(experiment_id='aaf6071946ae492eb28236dfaaae1b3c', training_iteration=29, episode_reward_mean=200.0, episode_len_mean=199.0, info={'kl_divergence': 0.0044262293, 'kl_coefficient': 5.364418029785157e-08, 'rollouts_time': 8.653595447540283, 'shuffle_time': 0.004950523376464844, 'load_time': 0.001409769058227539, 'sgd_time': 17.928891897201538, 'sample_throughput': 2264.278251704808}, timesteps_this_iter=40596, timesteps_total=1175799, time_this_iter_s=26.594194889068604, time_total_s=791.5903701782227)\n",
      "===> iteration 30\n",
      "total reward is  200.0\n",
      "trajectory length mean is  199.0\n",
      "timesteps: 40596\n",
      "Computing policy (iterations=30, stepsize=5e-05):\n",
      "           iter     total loss    policy loss        vf loss             kl        entropy\n",
      "              0    4.35266e+02   -3.08319e-04    4.35266e+02    2.10776e-03    4.27526e-01\n",
      "              1    2.40720e+02   -7.61174e-04    2.40721e+02    3.45036e-03    4.19994e-01\n",
      "              2    2.36998e+02   -8.81896e-04    2.36999e+02    3.99854e-03    4.19479e-01\n",
      "              3    2.35441e+02   -1.07847e-03    2.35442e+02    4.70390e-03    4.17272e-01\n",
      "              4    2.34223e+02   -1.07150e-03    2.34224e+02    3.85706e-03    4.21649e-01\n",
      "              5    2.33235e+02   -1.17518e-03    2.33236e+02    5.10215e-03    4.17450e-01\n",
      "              6    2.32398e+02   -1.17828e-03    2.32399e+02    4.82305e-03    4.18719e-01\n",
      "              7    2.31746e+02   -1.21495e-03    2.31747e+02    4.64805e-03    4.18254e-01\n",
      "              8    2.31157e+02   -1.29950e-03    2.31158e+02    4.87861e-03    4.17785e-01\n",
      "              9    2.30609e+02   -1.39972e-03    2.30610e+02    4.94095e-03    4.19480e-01\n",
      "             10    2.30190e+02   -1.48220e-03    2.30191e+02    4.99377e-03    4.20302e-01\n",
      "             11    2.29806e+02   -1.34094e-03    2.29807e+02    4.46113e-03    4.20018e-01\n",
      "             12    2.29445e+02   -1.65060e-03    2.29446e+02    5.04970e-03    4.16759e-01\n",
      "             13    2.29184e+02   -1.39427e-03    2.29186e+02    3.97048e-03    4.27381e-01\n",
      "             14    2.28921e+02   -1.57830e-03    2.28923e+02    5.05133e-03    4.17544e-01\n",
      "             15    2.28679e+02   -1.58620e-03    2.28680e+02    5.07342e-03    4.18473e-01\n",
      "             16    2.28502e+02   -1.55197e-03    2.28504e+02    3.99854e-03    4.23542e-01\n",
      "             17    2.28366e+02   -1.61775e-03    2.28368e+02    4.92199e-03    4.21899e-01\n",
      "             18    2.28143e+02   -1.68605e-03    2.28145e+02    5.06329e-03    4.18844e-01\n",
      "             19    2.28017e+02   -1.69485e-03    2.28019e+02    4.75091e-03    4.18969e-01\n",
      "             20    2.27856e+02   -1.65459e-03    2.27858e+02    4.86705e-03    4.21306e-01\n",
      "             21    2.27773e+02   -1.75107e-03    2.27775e+02    4.36608e-03    4.21358e-01\n",
      "             22    2.27641e+02   -1.74538e-03    2.27643e+02    4.81207e-03    4.21686e-01\n",
      "             23    2.27536e+02   -1.80534e-03    2.27538e+02    4.85849e-03    4.21879e-01\n",
      "             24    2.27426e+02   -1.81743e-03    2.27428e+02    4.72913e-03    4.21437e-01\n",
      "             25    2.27358e+02   -1.85084e-03    2.27360e+02    4.64843e-03    4.21928e-01\n",
      "             26    2.27272e+02   -1.83193e-03    2.27274e+02    4.48066e-03    4.25007e-01\n",
      "             27    2.27173e+02   -1.83213e-03    2.27175e+02    4.54141e-03    4.27301e-01\n",
      "             28    2.27077e+02   -1.88774e-03    2.27079e+02    4.52881e-03    4.21581e-01\n",
      "             29    2.27015e+02   -1.95655e-03    2.27017e+02    4.61908e-03    4.22736e-01\n",
      "kl div: 0.00461908\n",
      "kl coeff: 2.6822090148925785e-08\n",
      "rollouts time: 10.20729923248291\n",
      "shuffle time: 0.006977081298828125\n",
      "load time: 0.0014772415161132812\n",
      "sgd time: 21.003098249435425\n",
      "sgd examples/s: 1932.8576916546701\n",
      "total time so far: 946.4453911781311\n",
      "TrainingResult(experiment_id='aaf6071946ae492eb28236dfaaae1b3c', training_iteration=30, episode_reward_mean=200.0, episode_len_mean=199.0, info={'kl_divergence': 0.0046190806, 'kl_coefficient': 2.6822090148925785e-08, 'rollouts_time': 10.20729923248291, 'shuffle_time': 0.006977081298828125, 'load_time': 0.0014772415161132812, 'sgd_time': 21.003098249435425, 'sample_throughput': 1932.8576916546701}, timesteps_this_iter=40596, timesteps_total=1216395, time_this_iter_s=31.227142095565796, time_total_s=822.8175122737885)\n",
      "===> iteration 31\n",
      "total reward is  200.0\n",
      "trajectory length mean is  199.0\n",
      "timesteps: 40596\n",
      "Computing policy (iterations=30, stepsize=5e-05):\n",
      "           iter     total loss    policy loss        vf loss             kl        entropy\n",
      "              0    4.87756e+02    1.49615e-04    4.87755e+02    3.04436e-04    4.33032e-01\n",
      "              1    2.47214e+02   -2.37973e-04    2.47215e+02    1.37365e-03    4.47207e-01\n",
      "              2    2.40823e+02   -4.06316e-04    2.40823e+02    1.90817e-03    4.41591e-01\n",
      "              3    2.37967e+02   -5.25329e-04    2.37968e+02    2.31439e-03    4.39402e-01\n",
      "              4    2.36123e+02   -5.73702e-04    2.36124e+02    2.42711e-03    4.37534e-01\n",
      "              5    2.34857e+02   -5.67632e-04    2.34857e+02    2.74977e-03    4.32758e-01\n",
      "              6    2.33879e+02   -7.30742e-04    2.33879e+02    2.88539e-03    4.36793e-01\n",
      "              7    2.33115e+02   -8.60829e-04    2.33116e+02    2.81986e-03    4.35992e-01\n",
      "              8    2.32504e+02   -8.40953e-04    2.32505e+02    3.24478e-03    4.33735e-01\n",
      "              9    2.31959e+02   -9.03106e-04    2.31960e+02    2.77469e-03    4.36568e-01\n",
      "             10    2.31483e+02   -9.04160e-04    2.31484e+02    3.55746e-03    4.29585e-01\n",
      "             11    2.31038e+02   -9.70216e-04    2.31039e+02    3.22443e-03    4.31481e-01\n",
      "             12    2.30654e+02   -1.13432e-03    2.30655e+02    3.00231e-03    4.34767e-01\n",
      "             13    2.30325e+02   -1.20912e-03    2.30326e+02    4.12021e-03    4.31050e-01\n",
      "             14    2.29962e+02   -1.19972e-03    2.29963e+02    2.66990e-03    4.33247e-01\n",
      "             15    2.29661e+02   -1.25183e-03    2.29663e+02    3.63377e-03    4.32158e-01\n",
      "             16    2.29395e+02   -1.21517e-03    2.29396e+02    3.51679e-03    4.35285e-01\n",
      "             17    2.29141e+02   -1.31747e-03    2.29143e+02    3.25196e-03    4.32978e-01\n",
      "             18    2.28908e+02   -1.39881e-03    2.28909e+02    3.70971e-03    4.31199e-01\n",
      "             19    2.28679e+02   -1.38899e-03    2.28680e+02    3.54780e-03    4.34587e-01\n",
      "             20    2.28462e+02   -1.50126e-03    2.28463e+02    3.98516e-03    4.28089e-01\n",
      "             21    2.28271e+02   -1.42724e-03    2.28272e+02    3.16728e-03    4.36876e-01\n",
      "             22    2.28087e+02   -1.45240e-03    2.28088e+02    3.47989e-03    4.32502e-01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             23    2.27900e+02   -1.49257e-03    2.27901e+02    3.62888e-03    4.31002e-01\n",
      "             24    2.27759e+02   -1.57693e-03    2.27761e+02    3.64806e-03    4.35358e-01\n",
      "             25    2.27599e+02   -1.56277e-03    2.27600e+02    3.41298e-03    4.30819e-01\n",
      "             26    2.27437e+02   -1.55714e-03    2.27439e+02    3.94707e-03    4.33786e-01\n",
      "             27    2.27337e+02   -1.60365e-03    2.27339e+02    3.49833e-03    4.32107e-01\n",
      "             28    2.27179e+02   -1.62937e-03    2.27181e+02    3.68933e-03    4.32500e-01\n",
      "             29    2.27055e+02   -1.67347e-03    2.27057e+02    3.73381e-03    4.30750e-01\n",
      "kl div: 0.00373381\n",
      "kl coeff: 1.3411045074462893e-08\n",
      "rollouts time: 10.08564567565918\n",
      "shuffle time: 0.0047719478607177734\n",
      "load time: 0.001676321029663086\n",
      "sgd time: 19.660324335098267\n",
      "sgd examples/s: 2064.869292493139\n",
      "total time so far: 976.2047762870789\n",
      "TrainingResult(experiment_id='aaf6071946ae492eb28236dfaaae1b3c', training_iteration=31, episode_reward_mean=200.0, episode_len_mean=199.0, info={'kl_divergence': 0.003733814, 'kl_coefficient': 1.3411045074462893e-08, 'rollouts_time': 10.08564567565918, 'shuffle_time': 0.0047719478607177734, 'load_time': 0.001676321029663086, 'sgd_time': 19.660324335098267, 'sample_throughput': 2064.869292493139}, timesteps_this_iter=40596, timesteps_total=1256991, time_this_iter_s=29.759297847747803, time_total_s=852.5768101215363)\n",
      "===> iteration 32\n",
      "total reward is  200.0\n",
      "trajectory length mean is  199.0\n",
      "timesteps: 40596\n",
      "Computing policy (iterations=30, stepsize=5e-05):\n",
      "           iter     total loss    policy loss        vf loss             kl        entropy\n",
      "              0    4.16513e+02   -7.89665e-05    4.16513e+02    4.17407e-04    4.38937e-01\n",
      "              1    2.23255e+02   -5.31700e-04    2.23255e+02    1.39160e-03    4.43631e-01\n",
      "              2    2.18122e+02   -6.41937e-04    2.18123e+02    1.71212e-03    4.47872e-01\n",
      "              3    2.15395e+02   -7.86038e-04    2.15396e+02    1.66203e-03    4.41722e-01\n",
      "              4    2.13471e+02   -1.00458e-03    2.13472e+02    3.38755e-03    4.38799e-01\n",
      "              5    2.12192e+02   -9.93764e-04    2.12193e+02    2.38527e-03    4.38336e-01\n",
      "              6    2.11313e+02   -1.00214e-03    2.11314e+02    2.86681e-03    4.37122e-01\n",
      "              7    2.10763e+02   -1.10822e-03    2.10764e+02    2.59670e-03    4.40806e-01\n",
      "              8    2.10367e+02   -1.10233e-03    2.10368e+02    3.03691e-03    4.41182e-01\n",
      "              9    2.10036e+02   -1.18438e-03    2.10037e+02    2.90133e-03    4.40361e-01\n",
      "             10    2.09771e+02   -1.24821e-03    2.09772e+02    2.91617e-03    4.40303e-01\n",
      "             11    2.09551e+02   -1.26567e-03    2.09552e+02    2.91171e-03    4.38954e-01\n",
      "             12    2.09364e+02   -1.32969e-03    2.09366e+02    2.93458e-03    4.43474e-01\n",
      "             13    2.09176e+02   -1.39639e-03    2.09177e+02    3.47827e-03    4.37280e-01\n",
      "             14    2.08979e+02   -1.29650e-03    2.08980e+02    3.11486e-03    4.43461e-01\n",
      "             15    2.08864e+02   -1.41573e-03    2.08866e+02    3.00479e-03    4.42540e-01\n",
      "             16    2.08706e+02   -1.41942e-03    2.08708e+02    3.24595e-03    4.41625e-01\n",
      "             17    2.08547e+02   -1.53205e-03    2.08549e+02    3.45861e-03    4.39452e-01\n",
      "             18    2.08435e+02   -1.45180e-03    2.08437e+02    3.25854e-03    4.42033e-01\n",
      "             19    2.08312e+02   -1.44516e-03    2.08313e+02    3.12525e-03    4.44230e-01\n",
      "             20    2.08230e+02   -1.52403e-03    2.08232e+02    3.10616e-03    4.45083e-01\n",
      "             21    2.08107e+02   -1.51147e-03    2.08108e+02    3.38606e-03    4.39496e-01\n",
      "             22    2.07999e+02   -1.49518e-03    2.08001e+02    3.31379e-03    4.45649e-01\n",
      "             23    2.07889e+02   -1.59974e-03    2.07891e+02    3.50083e-03    4.41844e-01\n",
      "             24    2.07769e+02   -1.60826e-03    2.07771e+02    3.36829e-03    4.43984e-01\n",
      "             25    2.07639e+02   -1.64057e-03    2.07640e+02    3.51175e-03    4.43850e-01\n",
      "             26    2.07553e+02   -1.72516e-03    2.07554e+02    3.74463e-03    4.41726e-01\n",
      "             27    2.07507e+02   -1.66760e-03    2.07509e+02    3.27203e-03    4.42853e-01\n",
      "             28    2.07429e+02   -1.66362e-03    2.07430e+02    3.38845e-03    4.45132e-01\n",
      "             29    2.07313e+02   -1.71280e-03    2.07314e+02    3.26804e-03    4.41919e-01\n",
      "kl div: 0.00326804\n",
      "kl coeff: 6.705522537231446e-09\n",
      "rollouts time: 8.53756308555603\n",
      "shuffle time: 0.004244565963745117\n",
      "load time: 0.0016841888427734375\n",
      "sgd time: 17.820667028427124\n",
      "sgd examples/s: 2278.029208179592\n",
      "total time so far: 1002.5753483772278\n",
      "TrainingResult(experiment_id='aaf6071946ae492eb28236dfaaae1b3c', training_iteration=32, episode_reward_mean=200.0, episode_len_mean=199.0, info={'kl_divergence': 0.0032680421, 'kl_coefficient': 6.705522537231446e-09, 'rollouts_time': 8.53756308555603, 'shuffle_time': 0.004244565963745117, 'load_time': 0.0016841888427734375, 'sgd_time': 17.820667028427124, 'sample_throughput': 2278.029208179592}, timesteps_this_iter=40596, timesteps_total=1297587, time_this_iter_s=26.370372772216797, time_total_s=878.947182893753)\n"
     ]
    }
   ],
   "source": [
    "for i in range(30):\n",
    "    result = agent.train()\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checkpoint the current model. The call to `agent.save()` returns the path to the checkpointed model and can be used later to restore the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:/tmp/ray/CartPole-v0_PPOAgent_2017-09-18_23-12-09oy02h5hq/checkpoint-32 is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-09-18 23:28:54,456] /tmp/ray/CartPole-v0_PPOAgent_2017-09-18_23-12-09oy02h5hq/checkpoint-32 is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = agent.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use the trained policy to make predictions.\n",
    "\n",
    "**NOTE:** Here we are loading the trained policy in the same process, but in practice, this would often be done in a different process (probably on a different machine)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-09-18 23:28:54,701] PPOAgent algorithm created with logdir '/tmp/ray/CartPole-v0_PPOAgent_2017-09-18_23-28-54xl1oynzn'\n",
      "[2017-09-18 23:28:54,702] Making new env: CartPole-v0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-atari env, not using any observation preprocessor.\n",
      "Constructing fcnet [100, 100] <function tanh at 0x7f2bf7bd9268>\n",
      "Constructing fcnet [100, 100] <function tanh at 0x7f2bf7bd9268>\n",
      "Constructing fcnet [100, 100] <function tanh at 0x7f2bf7bd9268>\n",
      "Constructing fcnet [100, 100] <function tanh at 0x7f2bf7bd9268>\n",
      "Constructing fcnet [100, 100] <function tanh at 0x7f2bf7bd9268>\n",
      "Constructing fcnet [100, 100] <function tanh at 0x7f2bf7bd9268>\n",
      "Constructing fcnet [100, 100] <function tanh at 0x7f2bf7bd9268>\n",
      "Constructing fcnet [100, 100] <function tanh at 0x7f2bf7bd9268>\n",
      "Constructing fcnet [100, 100] <function tanh at 0x7f2bf7bd9268>\n",
      "Constructing fcnet [100, 100] <function tanh at 0x7f2bf7bd9268>\n",
      "INFO:tensorflow:Restoring parameters from /tmp/ray/CartPole-v0_PPOAgent_2017-09-18_23-12-09oy02h5hq/checkpoint-32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-09-18 23:28:57,851] Restoring parameters from /tmp/ray/CartPole-v0_PPOAgent_2017-09-18_23-12-09oy02h5hq/checkpoint-32\n"
     ]
    }
   ],
   "source": [
    "trained_config = config.copy()\n",
    "\n",
    "test_agent = PPOAgent('CartPole-v0', trained_config)\n",
    "test_agent.restore(checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use the trained policy to act in an environment. The key line is the call to `test_agent.compute_action(state)` which uses the trained policy to choose an action.\n",
    "\n",
    "**EXERCISE:** Verify that the reward received roughly matches up with the reward printed in the training logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-09-18 23:29:07,638] Making new env: CartPole-v0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200.0\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('CartPole-v0')\n",
    "state = env.reset()\n",
    "done = False\n",
    "cumulative_reward = 0\n",
    "\n",
    "while not done:\n",
    "    action = test_agent.compute_action(state)\n",
    "    state, reward, done, _ = env.step(action)\n",
    "    cumulative_reward += reward\n",
    "\n",
    "print(cumulative_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
